{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA_-eAkuEnLC"
      },
      "source": [
        "# Materials & Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Dqfh0oC9d7"
      },
      "source": [
        "## Prepare environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKhi2VbCKlKv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone \"https://github.com/sunwucheng/IDB_drilling_signal.git\" /content/drive/MyDrive/IDB_drilling_signal\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JJ3nLgyjX2H"
      },
      "source": [
        "## Display signal data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4rlRDFk7mas"
      },
      "source": [
        "### Load signal data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt6Ac0D3aTAx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.io as scio\n",
        "\n",
        "def read_matFile(signal_path):\n",
        "  signal_file = scio.loadmat(signal_path)\n",
        "  signal_value = signal_file['samples']\n",
        "  signal_value = np.squeeze(signal_value)\n",
        "  return signal_value\n",
        "\n",
        "def read_wavFile(signal_path):\n",
        "  signal_rate, signal_value = scio.wavfile.read(signal_path)\n",
        "  return signal_value, signal_rate\n",
        "\n",
        "import librosa\n",
        "\n",
        "def read_soundFile(signal_path):\n",
        "  signal_value, signal_rate = librosa.load(signal_path, sr=None, mono=True, offset=0.0, duration=None)\n",
        "  return signal_value, signal_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_yWjU4NvGWY"
      },
      "outputs": [],
      "source": [
        "RATE = 8192\n",
        "print(\"RATE: \", RATE, \"Hz (default in Matlab)\")\n",
        "\n",
        "S32h = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/3-2h.mat\")\n",
        "S41h = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-1h.mat\")\n",
        "S42h = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-2h.mat\")\n",
        "S43b = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-3b.mat\")\n",
        "print(\"---------------------------------------\")\n",
        "print(\"S32h : \", S32h.shape, len(S32h)/RATE, 's')\n",
        "print(\"S41h : \", S41h.shape, len(S41h)/RATE, 's')\n",
        "print(\"S42h : \", S42h.shape, len(S42h)/RATE, 's')\n",
        "print(\"S43b : \", S43b.shape, len(S43b)/RATE, 's')\n",
        "\n",
        "# S11 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_1.mat\")\n",
        "# S12 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_2.mat\")\n",
        "# S13 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_3.mat\")\n",
        "# S14 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_4.mat\")\n",
        "# S15 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_5.mat\")\n",
        "# S16 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_6.mat\")\n",
        "# S17 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_7.mat\")\n",
        "# S18 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_8.mat\")\n",
        "# S19 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_9.mat\")\n",
        "# print(\"---------------------------------------\")\n",
        "# print(\"S11 : \", S11.shape, len(S11)/RATE, 's')\n",
        "# print(\"S12 : \", S12.shape, len(S12)/RATE, 's')\n",
        "# print(\"S13 : \", S13.shape, len(S13)/RATE, 's')\n",
        "# print(\"S14 : \", S14.shape, len(S14)/RATE, 's')\n",
        "# print(\"S15 : \", S15.shape, len(S15)/RATE, 's')\n",
        "# print(\"S16 : \", S16.shape, len(S16)/RATE, 's')\n",
        "# print(\"S17 : \", S17.shape, len(S17)/RATE, 's')\n",
        "# print(\"S18 : \", S18.shape, len(S18)/RATE, 's')\n",
        "# print(\"S19 : \", S19.shape, len(S19)/RATE, 's')\n",
        "\n",
        "# S21 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_1.mat\")\n",
        "# S22 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_2.mat\")\n",
        "# S23 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_3.mat\")\n",
        "# S24 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_4.mat\")\n",
        "# S25 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_5.mat\")\n",
        "# S26 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_6.mat\")\n",
        "# S27 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_7.mat\")\n",
        "# S28 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_8.mat\")\n",
        "# S29 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_9.mat\")\n",
        "# print(\"---------------------------------------\")\n",
        "# print(\"S21 : \", S21.shape, len(S21)/RATE, 's')\n",
        "# print(\"S22 : \", S22.shape, len(S22)/RATE, 's')\n",
        "# print(\"S23 : \", S23.shape, len(S23)/RATE, 's')\n",
        "# print(\"S24 : \", S24.shape, len(S24)/RATE, 's')\n",
        "# print(\"S25 : \", S25.shape, len(S25)/RATE, 's')\n",
        "# print(\"S26 : \", S26.shape, len(S26)/RATE, 's')\n",
        "# print(\"S27 : \", S27.shape, len(S27)/RATE, 's')\n",
        "# print(\"S28 : \", S28.shape, len(S28)/RATE, 's')\n",
        "# print(\"S29 : \", S29.shape, len(S29)/RATE, 's')\n",
        "\n",
        "# S31 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_1.mat\")\n",
        "# S32 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_2.mat\")\n",
        "# S33 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_3.mat\")\n",
        "# S34 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_4.mat\")\n",
        "# S35 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_5.mat\")\n",
        "# S36 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_6.mat\")\n",
        "# S37 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_7.mat\")\n",
        "# S38 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_8.mat\")\n",
        "# S39 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_9.mat\")\n",
        "# print(\"---------------------------------------\")\n",
        "# print(\"S31 : \", S31.shape, len(S31)/RATE, 's')\n",
        "# print(\"S32 : \", S32.shape, len(S32)/RATE, 's')\n",
        "# print(\"S33 : \", S33.shape, len(S33)/RATE, 's')\n",
        "# print(\"S34 : \", S34.shape, len(S34)/RATE, 's')\n",
        "# print(\"S35 : \", S35.shape, len(S35)/RATE, 's')\n",
        "# print(\"S36 : \", S36.shape, len(S36)/RATE, 's')\n",
        "# print(\"S37 : \", S37.shape, len(S37)/RATE, 's')\n",
        "# print(\"S38 : \", S38.shape, len(S38)/RATE, 's')\n",
        "# print(\"S39 : \", S39.shape, len(S39)/RATE, 's')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm5FviVVnRxI"
      },
      "outputs": [],
      "source": [
        "# import soundfile\n",
        "\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/S32h.wav\"), S32h, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/S41h.wav\"), S41h, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/S42h.wav\"), S42h, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/S43b.wav\"), S43b, RATE)\n",
        "\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S11.wav\"), S11, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S12.wav\"), S12, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S13.wav\"), S13, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S14.wav\"), S14, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S15.wav\"), S15, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S16.wav\"), S16, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S17.wav\"), S17, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S18.wav\"), S18, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S19.wav\"), S19, RATE)\n",
        "\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S21.wav\"), S21, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S22.wav\"), S22, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S23.wav\"), S23, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S24.wav\"), S24, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S25.wav\"), S25, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S26.wav\"), S26, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S27.wav\"), S27, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S28.wav\"), S28, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S29.wav\"), S29, RATE)\n",
        "\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S31.wav\"), S31, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S32.wav\"), S32, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S33.wav\"), S33, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S34.wav\"), S34, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S35.wav\"), S35, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S36.wav\"), S36, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S37.wav\"), S37, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S38.wav\"), S38, RATE)\n",
        "# soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/S39.wav\"), S39, RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRDeP7mE7tsJ"
      },
      "source": [
        "### Plot signal data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laACxPu7uQWP"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def displayWaveform(signal, rate):\n",
        "  plt.figure(figsize=(20,6))\n",
        "  max = np.max(np.absolute(signal))*1.2\n",
        "  time = np.arange(0, len(SIGNAL)) / RATE\n",
        "  # plt.plot(time, signal)\n",
        "  librosa.display.waveshow(signal, sr=rate)\n",
        "  plt.title(\"Time domain waveform of speech signal\")\n",
        "  plt.xlabel(\"time (s)\")\n",
        "  plt.ylabel(\"amplitude\")\n",
        "  plt.xlim(0,len(SIGNAL)/RATE)\n",
        "  ymin, ymax = plt.ylim()\n",
        "  ylim = np.maximum(np.abs(ymin), np.abs(ymax))\n",
        "  plt.ylim(-ylim, ylim)\n",
        "\n",
        "def displaySpectrum(signal, rate):\n",
        "  plt.figure(figsize=(20,6)) \n",
        "  s = np.fft.fft(signal)\n",
        "  m = np.abs(s)\n",
        "  # f = np.linspace(0, rate, len(m))\n",
        "  # plt.plot(f, m)\n",
        "  n = len(signal)\n",
        "  f = np.fft.fftfreq(n, 1/rate)\n",
        "  plt.plot(f[:n//2],m[:n//2])\n",
        "  plt.title(\"Frequency domain spectral line of speech signal\")\n",
        "  plt.xlabel(\"Frequency (Hz)\")\n",
        "  plt.ylabel(\"amplitude\")\n",
        "  plt.xlim(0, rate//2)\n",
        "\n",
        "def displaySpectrogram(signal, rate, fftlen):    \n",
        "  plt.figure(figsize=(10,6))\n",
        "  # plt.specgram(signal, NFFT=fftlen, Fs=rate, noverlap=int(fftlen*0.25), window=np.hanning(fftlen))\n",
        "  signal_db = librosa.amplitude_to_db(np.abs(librosa.stft(signal, hop_length=int(fftlen*0.25))), ref=np.max) \n",
        "  librosa.display.specshow(signal_db, sr=rate, hop_length=int(fftlen*0.25), x_axis='time', y_axis='linear')\n",
        "  plt.title('Linear-frequency power spectrogram')\n",
        "  plt.xlabel('time (s)')\n",
        "  plt.ylabel('Frequency (Hz)')\n",
        "  plt.colorbar(format=\"%+2.0f dB\")\n",
        "\n",
        "def displayMelspectrogram(signal, rate):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  # melspectrogram = librosa.feature.melspectrogram(y=signal, sr=rate)\n",
        "  D = np.abs(librosa.stft(signal))**2\n",
        "  S = librosa.feature.melspectrogram(S=D, sr=rate)\n",
        "  S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "  img = librosa.display.specshow(S_dB, sr=rate, fmax=rate/2, x_axis='time', y_axis='mel') \n",
        "  plt.title('Mel-frequency spectrogram')\n",
        "  plt.colorbar(format='%+2.0f dB')\n",
        "\n",
        "def diaplayMFCC(signal, rate):\n",
        "  plt.figure(figsize=(8,6))\n",
        "  mfccs = librosa.feature.mfcc(y=signal, sr=rate)\n",
        "  librosa.display.specshow(mfccs, sr=rate, x_axis='time')\n",
        "\n",
        "def displayZCR(signal, rate):\n",
        "  plt.figure(figsize=(8,6))\n",
        "  zcrs = librosa.feature.zero_crossing_rate(signal)  \n",
        "  plt.plot(zcrs[0])\n",
        "\n",
        "from sklearn import preprocessing\n",
        "def normalize(x, axis=0):\n",
        "    return preprocessing.minmax_scale(x, axis=axis)\n",
        "\n",
        "def displayCentroids(signal, rate):\n",
        "  # spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=rate)[0]\n",
        "  # frames = range(len(spectral_centroids))\n",
        "  # times = librosa.frames_to_time(frames)\n",
        "  # librosa.display.waveshow(signal, sr=rate, alpha=0.4)\n",
        "  # plt.plot(times, normalize(spectral_centroids), color='r')\n",
        "\n",
        "  cent = librosa.feature.spectral_centroid(y=signal, sr=rate) \n",
        "  S, phase = librosa.magphase(librosa.stft(y=signal))\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  librosa.feature.spectral_centroid(S=S)\n",
        "  freqs, times, D = librosa.reassigned_spectrogram(signal, fill_nan=True)\n",
        "  librosa.feature.spectral_centroid(S=np.abs(D), freq=freqs)\n",
        "  times = librosa.times_like(cent)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  ax[0].semilogy(times, cent[0], label='Spectral centroid')\n",
        "  ax[0].set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])\n",
        "  ax[0].legend()\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[1])\n",
        "  ax[1].plot(times, cent.T, label='Spectral centroid', color='w')\n",
        "  ax[1].set(title='log Power spectrogram')\n",
        "  ax[1].legend(loc='lower right')\n",
        "\n",
        "def displayBandwidth(signal, rate):\n",
        "  # spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(y=signal+0.01, sr=rate)[0]\n",
        "  # spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(y=signal+0.01, sr=rate, p=3)[0]\n",
        "  # spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(y=signal+0.01, sr=rate, p=4)[0]\n",
        "  # librosa.display.waveshow(signal, sr=rate, alpha=0.4)\n",
        "  # normal2 = preprocessing.minmax_scale(spectral_bandwidth_2, axis=0)\n",
        "  # normal3 = preprocessing.minmax_scale(spectral_bandwidth_3, axis=0)\n",
        "  # normal4 = preprocessing.minmax_scale(spectral_bandwidth_4, axis=0)\n",
        "  # spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=rate)[0]\n",
        "  # frames = range(len(spectral_centroids))\n",
        "  # times = librosa.frames_to_time(frames)\n",
        "  # plt.plot(times, normal2, color='r')\n",
        "  # plt.plot(times, normal3, color='g')\n",
        "  # plt.plot(times, normal4, color='y')\n",
        "  # plt.legend(('p = 2', 'p = 3', 'p = 4'))\n",
        "\n",
        "  spec_bw = librosa.feature.spectral_bandwidth(y=signal, sr=rate)\n",
        "  S, phase = librosa.magphase(librosa.stft(y=signal))\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  librosa.feature.spectral_bandwidth(S=S)\n",
        "  freqs, times, D = librosa.reassigned_spectrogram(signal, fill_nan=True)\n",
        "  librosa.feature.spectral_bandwidth(S=np.abs(D), freq=freqs)\n",
        "  times = librosa.times_like(spec_bw)\n",
        "  centroid = librosa.feature.spectral_centroid(S=S)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  ax[0].semilogy(times, spec_bw[0], label='Spectral bandwidth')\n",
        "  ax[0].set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])\n",
        "  ax[0].legend()\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  librosa.display.specshow(S_db, y_axis='log', x_axis='time', ax=ax[1])\n",
        "  ax[1].set(title='log Power spectrogram')\n",
        "  ax[1].fill_between(times, np.maximum(0, centroid[0] - spec_bw[0]), np.minimum(centroid[0] + spec_bw[0], rate/2), alpha=0.5, label='Centroid +- bandwidth')\n",
        "  ax[1].plot(times, centroid[0], label='Spectral centroid', color='w')\n",
        "  ax[1].legend(loc='lower right')\n",
        "\n",
        "def displayRolloff(signal, rate):\n",
        "  # spectral_rolloff = librosa.feature.spectral_rolloff(y=signal+0.01, sr=rate)[0]\n",
        "  # librosa.display.waveshow(signal, sr=rate, alpha=0.4)\n",
        "  # spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=rate)[0]\n",
        "  # frames = range(len(spectral_centroids))\n",
        "  # times = librosa.frames_to_time(frames)\n",
        "  # normals = preprocessing.minmax_scale(spectral_rolloff, axis=0)\n",
        "  # plt.plot(times, normals, color='r')\n",
        "\n",
        "  librosa.feature.spectral_rolloff(y=signal, sr=rate)\n",
        "  rolloff = librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.99)\n",
        "  rolloff_min = librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.01)\n",
        "  S, phase = librosa.magphase(librosa.stft(signal))\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  librosa.feature.spectral_rolloff(S=S, sr=rate)\n",
        "  librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.95)\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  librosa.display.specshow(S_db, y_axis='log', x_axis='time', ax=ax)\n",
        "  ax.plot(librosa.times_like(rolloff), rolloff[0], label='Roll-off frequency (0.99)')\n",
        "  ax.plot(librosa.times_like(rolloff), rolloff_min[0], color='w', label='Roll-off frequency (0.01)')\n",
        "  ax.legend(loc='lower right')\n",
        "  ax.set(title='log Power spectrogram')\n",
        "\n",
        "def displayChromastft(signal, rate, fftlen):\n",
        "  # plt.figure(figsize=(20, 6))\n",
        "  # chromagram = librosa.feature.chroma_stft(signal, sr=rate, hop_length=int(fftlen*0.25))\n",
        "  # librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=fftlen*0.25, cmap='coolwarm')\n",
        "\n",
        "  S = np.abs(librosa.stft(signal))\n",
        "  chroma = librosa.feature.chroma_stft(S=S, sr=rate)\n",
        "  S = np.abs(librosa.stft(signal, n_fft=fftlen))**2\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  chroma = librosa.feature.chroma_stft(S=S, sr=rate)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[0])\n",
        "  fig.colorbar(img, ax=[ax[0]])\n",
        "  ax[0].label_outer()\n",
        "  img = librosa.display.specshow(chroma, x_axis='time', y_axis='chroma', ax=ax[1])\n",
        "  fig.colorbar(img, ax=[ax[1]])\n",
        "\n",
        "def displayChromacqt(signal, rate, n_chroma, n_fft):\n",
        "  chroma_stft = librosa.feature.chroma_stft(y=signal, sr=rate, n_chroma=n_chroma, n_fft=n_fft)\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
        "  img1 = librosa.display.specshow(chroma_stft, x_axis='time', y_axis='chroma', ax=ax[0])\n",
        "  ax[0].set(title='chroma_stft')\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  img2 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[1])\n",
        "  ax[1].set(title='chroma_cqt')\n",
        "  fig.colorbar(img2, ax=ax)\n",
        "\n",
        "def displayChromacens(signal, rate):\n",
        "  chroma_cens = librosa.feature.chroma_cens(y=signal, sr=rate)\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
        "  img1 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[0])\n",
        "  ax[0].set(title='chroma_cq')\n",
        "  ax[0].label_outer()\n",
        "  img2 = librosa.display.specshow(chroma_cens, x_axis='time', y_axis='chroma', ax=ax[1])\n",
        "  ax[1].set(title='chroma_cens')\n",
        "  fig.colorbar(img1, ax=ax)\n",
        "\n",
        "def displayChromavqt(signal, rate, n_bins):\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate, n_chroma=n_bins)\n",
        "  chroma_vq = librosa.feature.chroma_vqt(y=signal, sr=rate, intervals='ji5', bins_per_octave=n_bins)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  img1 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[0], bins_per_octave=n_bins)\n",
        "  ax[0].set(ylabel='chroma_cqt')\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  img2 = librosa.display.specshow(chroma_vq, y_axis='chroma_fjs', x_axis='time', ax=ax[1], bins_per_octave=n_bins, intervals='ji5')\n",
        "  ax[1].set(ylabel='chroma_vqt')\n",
        "  fig.colorbar(img2, ax=ax)\n",
        "\n",
        "def plot_wave(signal, rate):  \n",
        "  displayWaveform(signal, rate)\n",
        "  displaySpectrum(signal, rate)\n",
        "  displaySpectrogram(signal, rate, fftlen=512)\n",
        "  displayMelspectrogram(signal, rate)\n",
        "  diaplayMFCC(signal, rate)\n",
        "  displayZCR(signal, rate)\n",
        "  displayCentroids(signal, rate)\n",
        "  displayBandwidth(signal, rate)\n",
        "  displayRolloff(signal, rate)\n",
        "  displayChromastft(signal, rate, fftlen=512)\n",
        "  # displayChromacqt(signal, rate, n_chroma=12, n_fft=512)\n",
        "  # displayChromacens(signal, rate)\n",
        "  # displayChromavqt(signal, rate, n_bins=24)\n",
        "\n",
        "SIGNAL = S32h[-40*RATE:]\n",
        "plot_wave(SIGNAL, RATE)\n",
        "\n",
        "import IPython\n",
        "\n",
        "IPython.display.Audio(data=SIGNAL, rate=RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP1CxFHYIul5"
      },
      "source": [
        "### Pick signal cut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG-MYKwbo1Uf"
      },
      "outputs": [],
      "source": [
        "def cut_signal(signal_series):\n",
        "\n",
        "  sample_size = int(RATE/2)         # 4096\n",
        "  sample_step = int(sample_size/4)  # 512\n",
        "  sample_data = []\n",
        "\n",
        "  for i in range((len(signal_series)-sample_size) // sample_step):\n",
        "    sample_data.append(signal_series[i*sample_step : (i*sample_step+sample_size)])\n",
        "\n",
        "  sample_data = np.stack(sample_data)\n",
        "  sample_data = np.squeeze(sample_data)\n",
        "\n",
        "  # np.random.seed(42)\n",
        "  # np.random.shuffle(sample_data)\n",
        "  \n",
        "  return sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHVUZzXIE64f"
      },
      "source": [
        "# Classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data pre-treatment"
      ],
      "metadata": {
        "id": "eFaBo2s6K3Lk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYvGlEF8nYad"
      },
      "outputs": [],
      "source": [
        "# S32hCX 00:00-17:36 (02:00-12:00)\n",
        "# S41hCX 01:21-14:03 (02:00-12:00)\n",
        "# S42hCX 00:00-21:24 (02:00-12:00)\n",
        "# S43bCX 01:01-37:31 (02:00-12:00 14:00-24:00 26:00-36:00)\n",
        "\n",
        "S32hCX = cut_signal(S32h[120*RATE:720*RATE])\n",
        "S41hCX = cut_signal(S41h[120*RATE:720*RATE])\n",
        "S42hCX = cut_signal(S42h[120*RATE:720*RATE])\n",
        "S43bCX1 = cut_signal(S43b[120*RATE:720*RATE])\n",
        "S43bCX2 = cut_signal(S43b[840*RATE:1440*RATE])\n",
        "S43bCX3 = cut_signal(S43b[1560*RATE:2160*RATE])\n",
        "\n",
        "print(S32hCX.shape)\n",
        "print(S41hCX.shape)\n",
        "print(S42hCX.shape)\n",
        "print(S43bCX1.shape)\n",
        "print(S43bCX2.shape)\n",
        "print(S43bCX3.shape)\n",
        "\n",
        "S32hCY = np.repeat(0, len(S32hCX))\n",
        "S41hCY = np.repeat(0, len(S41hCX))\n",
        "S42hCY = np.repeat(0, len(S42hCX))\n",
        "S43bCY1 = np.repeat(1, len(S43bCX1))\n",
        "S43bCY2 = np.repeat(1, len(S43bCX2))\n",
        "S43bCY3 = np.repeat(1, len(S43bCX3))\n",
        "\n",
        "print(S32hCY.shape)\n",
        "print(S41hCY.shape)\n",
        "print(S42hCY.shape)\n",
        "print(S43bCY1.shape)\n",
        "print(S43bCY2.shape)\n",
        "print(S43bCY3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4Puu0AAUTtI"
      },
      "outputs": [],
      "source": [
        "X_set = np.concatenate((S32hCX, S41hCX, S42hCX, S43bCX1, S43bCX2, S43bCX3), axis=0)\n",
        "print(X_set.shape)\n",
        "X_set = X_set.reshape((X_set.shape[0], X_set.shape[1], 1))\n",
        "print(X_set.shape)\n",
        "print(X_set[0])\n",
        "\n",
        "Y_set = np.concatenate((S32hCY, S41hCY, S42hCY, S43bCY1, S43bCY2, S43bCY3), axis=0)\n",
        "num_classes = len(np.unique(Y_set))\n",
        "print(Y_set.shape)\n",
        "print(Y_set)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "Y_set = to_categorical(Y_set, num_classes=num_classes)\n",
        "print(Y_set.shape)\n",
        "print(Y_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NytsoEcYnNhJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_set, Y_set, test_size=0.33, random_state=42)\n",
        "print(x_train.shape)\n",
        "print(x_train[0])\n",
        "print(x_test.shape)\n",
        "print(x_test[0])\n",
        "print(y_train.shape)\n",
        "print(y_train)\n",
        "print(y_test.shape)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byeqEwa-jRXi"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del S32hCX, S41hCX, S42hCX, S43bCX1, S43bCX2, S43bCX3, S32hCY, S41hCY, S42hCY, S43bCY1, S43bCY2, S43bCY3, X_set, Y_set\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wposm1JjnPVi"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpiifOj8A5-5"
      },
      "source": [
        "## 1D pure FC model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cQ2v297BBXX"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Flatten()(input_layer)\n",
        "  x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(x_train.shape[1], activation=\"relu\")(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1RkpMgFLLsR"
      },
      "source": [
        "## 1D pure Conv model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMU-Vjz3DRNW"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yF2rdDXjghc"
      },
      "source": [
        "## 1D mix Conv model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAWVESHNjlNW"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=32, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(input_layer)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=128, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=1024, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV9UyRhCK9IS"
      },
      "source": [
        "## Compile&Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzdCmhMnBBZ3"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='sgd', \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy',\n",
        "                       keras.metrics.AUC(),\n",
        "                       keras.metrics.Precision(),\n",
        "                       keras.metrics.Recall()])\n",
        "\n",
        "callbacks = [\n",
        "            #  keras.callbacks.ModelCheckpoint(\"best_model.h5\",\n",
        "            #                                  monitor=\"loss\",\n",
        "            #                                  mode=\"min\",\n",
        "            #                                  save_best_only=True),\n",
        "             keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                           mode=\"min\",\n",
        "                                           patience=10,\n",
        "                                           restore_best_weights=True),\n",
        "             keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
        "                                               factor=0.2, \n",
        "                                               patience=2,\n",
        "                                               min_lr=0.000001),\n",
        "            #  keras.callbacks.TensorBoard(log_dir=\"/content/drive/MyDrive/IDB_drilling_signal/outputs/logs\",\n",
        "            #                              histogram_freq=1,\n",
        "            #                              write_graph=True, \n",
        "            #                              write_images=True)\n",
        "            ]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_split=0.2, \n",
        "                    epochs=300, \n",
        "                    batch_size=64, \n",
        "                    callbacks=callbacks, \n",
        "                    shuffle=True)\n",
        "\n",
        "model.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/model.h5\")\n",
        "np.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/history.npy\", history.history, allow_pickle=True)\n",
        "hist = np.load(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/history.npy\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZc9ctYii2-R"
      },
      "source": [
        "## Plot history metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eNbjUMfrBBb6"
      },
      "outputs": [],
      "source": [
        "def plot_history_metrics(history):\n",
        "  \n",
        "  total_plots = len(history)\n",
        "  cols = total_plots // 2\n",
        "  rows = total_plots // cols\n",
        "\n",
        "  if total_plots % cols != 0:\n",
        "    rows += 1\n",
        "\n",
        "  pos = range(1, total_plots + 1)\n",
        "\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  for i, (key, value) in enumerate(history.items()):\n",
        "    plt.subplot(rows, cols, pos[i])\n",
        "    plt.plot(range(len(value)), value)\n",
        "    plt.title(str(key))\n",
        "\n",
        "plot_history_metrics(hist)\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir \"/content/drive/MyDrive/IDB_drilling_signal/output/logs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1r3bvw4LTq6"
      },
      "source": [
        "## Test-set evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pSULLYM8dWk2"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy, test_auc, test_precision, tes_recall = model.evaluate(x_test, y_test)\n",
        "print(\"Test loss\", test_loss)\n",
        "print(\"Test accuracy\", test_accuracy)\n",
        "print(\"test_auc\", test_auc) \n",
        "print(\"test_precision\", test_precision) \n",
        "print(\"tesrecall\", tes_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LGUbJBchdz0x"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def show_cm(y_true, y_pred):\n",
        "\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "  plt.xticks([0,1])\n",
        "  plt.yticks([0,1])\n",
        "  plt.xlabel(\"Predict\")\n",
        "  plt.ylabel(\"True\")\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "  plt.text(x=0-0.1, y=0, s=\"TP:\"+str(tp), color='black')\n",
        "  plt.text(x=1-0.1, y=0, s=\"FN:\"+str(fn), color='black')\n",
        "  plt.text(x=0-0.1, y=1, s=\"FP:\"+str(fp), color='black')\n",
        "  plt.text(x=1-0.1, y=1, s=\"TN:\"+str(tn), >color='black')\n",
        "  precision = tp/(tp + fp)\n",
        "  recall = tp/(tp + tn)\n",
        "  print(\"precision:\", precision)\n",
        "  print(\"recall:\", recall)\n",
        "  plt.show()\n",
        "\n",
        "y_test_pred = model.predict(x_test)\n",
        "show_cm(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAQJZnnvpeT0"
      },
      "source": [
        "# Regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV62gvbXUujh"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWNN400DIpCg"
      },
      "outputs": [],
      "source": [
        "# S31h 15:10:51-15:18:26 (15:10:00-15:19:22) [54:-56,1:-1] 455s\n",
        "# S32h 15:25:33-15:43:18 (15:25:00-15:43:22) [36:-4 ,1:-1] 1065s\n",
        "# S33b 15:48:20-16:13:46 (15:48:00-16:13:50) [23:-4 ,1:-1] 1526s\n",
        "# S41h 16:26:25-16:39:33 (16:26:00-16:39:50) [28:-17,1:-1] 788s\n",
        "# S42h 16:54:57-17:16:30 (16:54:30-17:16:50) [30:-20,1:-1] 1293s\n",
        "# S43b 17:24:00-18:00:24 (17:24:00-18:00:50) [3:-26 ,1:-1] 2184s\n",
        "\n",
        "# S32h matFile[0:12*60*RATE] xlsFile[15:31:18-15:43:18]\n",
        "\n",
        "# S32h = S32h[0:12*60*RATE]\n",
        "# S41h = S41h[0:12*60*RATE]\n",
        "# S42h = S42h[0:12*60*RATE]\n",
        "# S43b = S43b[0:12*60*RATE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJBJ9ZDJjr6M"
      },
      "source": [
        "## Data pre-processment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhqzcDzbkRYh"
      },
      "source": [
        "### Enlarge parameter data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujBYos05kr8Y"
      },
      "outputs": [],
      "source": [
        "def enlarge_value(array, length):\n",
        "  L = array.shape[0]\n",
        "  W = array.shape[1]\n",
        "  new_section = np.zeros([(L-1)*length, W-1])\n",
        "  for i in range(L - 1):   \n",
        "    new_second = np.zeros([length, W-1])\n",
        "    for j in range(W - 1):\n",
        "      start_value = float(array[i, j+1])\n",
        "      end_value = float(array[i+1, j+1])\n",
        "      new_second[:,j] = np.linspace(start_value, end_value, length + 2)[1:-1]  \n",
        "    new_section[i*length:(i+1)*length,:] = new_second\n",
        "  return new_section\n",
        "\n",
        "S32hY = enlarge_value(S32h_label, RATE)\n",
        "print(type(S32hY), S32hY.shape)\n",
        "print(S32hY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR7UxeNklWwz"
      },
      "source": [
        "### Pick corresponding signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP80s_nDnE8u"
      },
      "outputs": [],
      "source": [
        "S32hX = S32h[0:len(S32hY)]\n",
        "print(type(S32hX), S32hX.shape)\n",
        "print(S32hX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZU4vSh3jywY"
      },
      "source": [
        "### Load parameter table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b8erT_Vk7l1"
      },
      "outputs": [],
      "source": [
        "# S31h 15:10:51-15:18:26 (15:10:00-15:19:22) [54:-56,1:-1] 455s\n",
        "# S32h 15:25:33-15:43:18 (15:25:00-15:43:22) [36:-4 ,1:-1] 1065s\n",
        "# S33b 15:48:20-16:13:46 (15:48:00-16:13:50) [23:-4 ,1:-1] 1526s\n",
        "# S41h 16:26:25-16:39:33 (16:26:00-16:39:50) [28:-17,1:-1] 788s\n",
        "# S42h 16:54:57-17:16:30 (16:54:30-17:16:50) [30:-20,1:-1] 1293s\n",
        "# S43b 17:24:00-18:00:24 (17:24:00-18:00:50) [3:-26 ,1:-1] 2184s\n",
        "\n",
        "# S11 10:58:07-11:01:48 (10:58:00-11:04:15)\n",
        "# S12 09:16:18-09:18:26 (09:16:00-09:18:50)\n",
        "# S13 09:21:30-09:23:03 (09:21:00-09:23:50)\n",
        "# S14 09:45:38-09:46:22 (09:45:00-09:46:50)\n",
        "# S15 09:49:44-09:50:13 (09:49:00-09:50:50)\n",
        "# S16 09:53:08- (09:53:00-)\n",
        "# ......\n",
        "\n",
        "S32h_dict = {\"path\":\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/3-2h.xls\", \"index1\":381, \"index2\":1102}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxIUevQUkm4m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_table(SIGNAL_dict):\n",
        "  SIGNAL_pd = pd.read_excel(SIGNAL_dict[\"path\"])\n",
        "  IPython.display.display(SIGNAL_pd)\n",
        "  SIGNAL_arr = SIGNAL_pd.values[SIGNAL_dict[\"index1\"]:SIGNAL_dict[\"index2\"],1:-1]\n",
        "  print(type(SIGNAL_arr), SIGNAL_arr.shape, len(SIGNAL_arr)-1, \"s\")\n",
        "  print(SIGNAL_arr)\n",
        "  return SIGNAL_arr\n",
        "\n",
        "S32h_label = load_table(S32h_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLVG3EhnFMmh"
      },
      "source": [
        "## Transpose autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJxHVtR69Qj_"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.Conv1D(filters=64, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Dropout(rate=0.2)(x)\n",
        "  x = keras.Conv1D(filters=32, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Dropout(rate=0.2)(x)\n",
        "  x = keras.Conv1D(filters=16, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Dropout(rate=0.2)(x)\n",
        "\n",
        "  x = keras.Conv1DTranspose(filters=16, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Conv1DTranspose(filters=32, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Conv1DTranspose(filters=64, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Conv1DTranspose(filters=1, kernel_size=6, padding=\"same\")(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "# keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybM42yrhGqwv"
      },
      "outputs": [],
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)]\n",
        "\n",
        "history = model.fit(x_train, x_train,\n",
        "                    epochs=300,\n",
        "                    batch_size=64,                    \n",
        "                    validation_split=0.2,\n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar7a0PP1Gq1L"
      },
      "outputs": [],
      "source": [
        "# Get train MAE loss.\n",
        "x_train_pred = model.predict(x_train)\n",
        "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
        "\n",
        "plt.hist(train_mae_loss, bins=50)\n",
        "plt.xlabel(\"Train MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "# Get reconstruction loss threshold.\n",
        "threshold = np.max(train_mae_loss)\n",
        "print(\"Reconstruction error threshold: \", threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrWp0lUEGq3j"
      },
      "outputs": [],
      "source": [
        "# Checking how the first sequence is learnt\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.plot(x_train[0])\n",
        "plt.plot(x_train_pred[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNEykUEdGq5u"
      },
      "outputs": [],
      "source": [
        "# Get test MAE loss.\n",
        "x_test_pred = model.predict(x_test)\n",
        "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
        "test_mae_loss = test_mae_loss.reshape((-1))\n",
        "\n",
        "plt.hist(test_mae_loss, bins=50)\n",
        "plt.xlabel(\"test MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "# Detect all the samples which are anomalies.\n",
        "anomalies = test_mae_loss > threshold\n",
        "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
        "print(\"Indices of anomaly samples: \", np.where(anomalies))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P675rHgiXtsF"
      },
      "source": [
        "## Self-made autoencoder-2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f2YevYNV6SQ"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "input_size = 1024\n",
        "hidden_size = 256\n",
        "code_size = 64\n",
        "latent_dim = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7cLFMexV6Uj"
      },
      "outputs": [],
      "source": [
        "x = Input(shape=(input_size,))\n",
        "h1 = Dense(hidden_size, activation='relu')(x)\n",
        "h2 = Dense(code_size, activation='relu')(h1)\n",
        "l = Dense(latent_dim, activation='relu')(h2)\n",
        "h3 = Dense(code_size, activation='relu')(l)\n",
        "h4 = Dense(hidden_size, activation='relu')(h3)\n",
        "r = Dense(input_size, activation='sigmoid')(h4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WVEZFzLV6Ww"
      },
      "outputs": [],
      "source": [
        "autoencoder = Model(x, r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-iawz8ncfYL"
      },
      "outputs": [],
      "source": [
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "plt.figure()\n",
        "plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], c=Y_train)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2SBTshFV6ZW"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(X_train, X_train, \n",
        "                          batch_size=batch_size, \n",
        "                          epochs=epochs, \n",
        "                          verbose=1, \n",
        "                          validation_data=(X_test, X_test),\n",
        "                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFH2Exp5V6dV"
      },
      "outputs": [],
      "source": [
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "plt.figure()\n",
        "plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], c=Y_train)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZQeTBkFdxGJ"
      },
      "source": [
        "## Self-made autoencoder-3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrwffnUUdxGV"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "input_size = 1024\n",
        "hidden_size = 256\n",
        "code_size = 64\n",
        "latent_dim = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSlj0KThdxGW"
      },
      "outputs": [],
      "source": [
        "x = Input(shape=(input_size,))\n",
        "h1 = Dense(hidden_size, activation='relu')(x)\n",
        "h2 = Dense(code_size, activation='relu')(h1)\n",
        "l = Dense(latent_dim, activation='relu')(h2)\n",
        "h3 = Dense(code_size, activation='relu')(l)\n",
        "h4 = Dense(hidden_size, activation='relu')(h3)\n",
        "r = Dense(input_size, activation='sigmoid')(h4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD0qqHskdxGW"
      },
      "outputs": [],
      "source": [
        "autoencoder = Model(x, r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS_j5KvFdxGW"
      },
      "outputs": [],
      "source": [
        "# encoder = Model(x, l)\n",
        "# X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "# plt.figure()\n",
        "# plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], X_train_encoded[:, 2], c=Y_train)\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "\n",
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "ax.scatter(X_train_encoded[:,0], X_train_encoded[:,1], X_train_encoded[:,2], c=Y_train)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdAjjqAddxGX"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(X_train, X_train, \n",
        "                          batch_size=batch_size, \n",
        "                          epochs=epochs, \n",
        "                          verbose=1, \n",
        "                          validation_data=(X_test, X_test),\n",
        "                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBTz1HVSdxGX"
      },
      "outputs": [],
      "source": [
        "# encoder = Model(x, l)\n",
        "# X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "# plt.figure()\n",
        "# plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], X_train_encoded[:, 2], c=Y_train)\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "\n",
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "ax.scatter(X_train_encoded[:,0], X_train_encoded[:,1], X_train_encoded[:,2], c=Y_train)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mA_-eAkuEnLC",
        "G6Dqfh0oC9d7",
        "0JJ3nLgyjX2H",
        "QHVUZzXIE64f",
        "eFaBo2s6K3Lk",
        "TpiifOj8A5-5",
        "u1RkpMgFLLsR",
        "7yF2rdDXjghc",
        "SV9UyRhCK9IS",
        "qZc9ctYii2-R",
        "A1r3bvw4LTq6",
        "pAQJZnnvpeT0",
        "MJBJ9ZDJjr6M",
        "yLVG3EhnFMmh",
        "P675rHgiXtsF",
        "nZQeTBkFdxGJ"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}