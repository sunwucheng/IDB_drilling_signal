{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA_-eAkuEnLC"
      },
      "source": [
        "# IDB_drilling_signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Dqfh0oC9d7"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QJS-S-I2f8E",
        "outputId": "c19a2bc1-e89a-4398-e504-2843c453f242"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wUqY3572Qts"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import gc\n",
        "import IPython\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import scipy.io as scio\n",
        "import soundfile\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "\n",
        "HOST_path = \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4rlRDFk7mas"
      },
      "source": [
        "## Load signal data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt6Ac0D3aTAx"
      },
      "outputs": [],
      "source": [
        "def read_matFile(signal_path):\n",
        "  signal_file = scio.loadmat(signal_path)\n",
        "  signal_value = signal_file['samples']\n",
        "  signal_value = np.squeeze(signal_value)\n",
        "  return signal_value\n",
        "\n",
        "def read_wavFile(signal_path):\n",
        "  signal_rate, signal_value = scio.wavfile.read(signal_path)\n",
        "  return signal_value, signal_rate\n",
        "\n",
        "def read_soundFile(signal_path):\n",
        "  signal_value, signal_rate = librosa.load(signal_path, sr=None, mono=True, offset=0.0, duration=None)\n",
        "  return signal_value, signal_rate\n",
        "\n",
        "RATE = 8192\n",
        "\n",
        "S32h = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/rock_drilling_signal/experiment1/matFile/3-2h.mat\"))\n",
        "S41h = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/rock_drilling_signal/experiment1/matFile/4-1h.mat\"))\n",
        "S42h = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/rock_drilling_signal/experiment1/matFile/4-2h.mat\"))\n",
        "S43b = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/rock_drilling_signal/experiment1/matFile/4-3b.mat\"))\n",
        "\n",
        "print(\"RATE: \", RATE, \"Hz (default in Matlab)\")\n",
        "print(\"---------------------------------------\")\n",
        "print(\"S32h : \", S32h.shape, len(S32h)/RATE, 's')\n",
        "print(\"S41h : \", S41h.shape, len(S41h)/RATE, 's')\n",
        "print(\"S42h : \", S42h.shape, len(S42h)/RATE, 's')\n",
        "print(\"S43b : \", S43b.shape, len(S43b)/RATE, 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlC7WDV_2Qtv"
      },
      "source": [
        "## Convert signal data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzPbruAO2Qtv"
      },
      "outputs": [],
      "source": [
        "dir_path = os.path.join(HOST_path, \"IDB_drilling_signal/rock_drilling_signal/experiment1/matFile\")\n",
        "path_list = os.listdir(dir_path)\n",
        "path_list.sort()\n",
        "for i,j in enumerate(path_list):\n",
        "    name = os.path.splitext(j)\n",
        "    mat_path = os.path.join(dir_path, j)\n",
        "    mat_file = read_matFile(mat_path)\n",
        "    wav_path = os.path.join(dir_path, name[0]+\".wav\")\n",
        "    soundfile.write(wav_path, mat_file, RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUsYu9ZG2Qtw"
      },
      "source": [
        "## Plot signal data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "kxE1YGy12Qtw"
      },
      "outputs": [],
      "source": [
        "def displayWaveform(signal, rate):\n",
        "  plt.figure(figsize=(20,6))\n",
        "  max = np.max(np.absolute(signal))*1.2\n",
        "  time = np.arange(0, len(SIGNAL)) / RATE\n",
        "  plt.plot(time, signal)\n",
        "  plt.title(\"Time domain waveform of speech signal\")\n",
        "  plt.xlabel(\"time (s)\")\n",
        "  plt.ylabel(\"amplitude\")\n",
        "  plt.xlim(0,len(SIGNAL)/RATE)\n",
        "  ymin, ymax = plt.ylim()\n",
        "  ylim = np.maximum(np.abs(ymin), np.abs(ymax))\n",
        "  plt.ylim(-ylim, ylim)\n",
        "\n",
        "def displaySpectrum(signal, rate):\n",
        "  plt.figure(figsize=(20,6)) \n",
        "  s = np.fft.fft(signal)\n",
        "  m = np.abs(s)\n",
        "  n = len(signal)\n",
        "  f = np.fft.fftfreq(n, 1/rate)\n",
        "  plt.plot(f[:n//2],m[:n//2])\n",
        "  plt.title(\"Frequency domain spectral line of speech signal\")\n",
        "  plt.xlabel(\"Frequency (Hz)\")\n",
        "  plt.ylabel(\"amplitude\")\n",
        "  plt.xlim(0, rate//2)\n",
        "\n",
        "def displaySpectrogram(signal, rate, fftlen):    \n",
        "  plt.figure(figsize=(8,6))\n",
        "  plt.specgram(signal, NFFT=fftlen, Fs=rate, noverlap=int(fftlen*0.25), window=np.hanning(fftlen))\n",
        "  plt.title('Linear-frequency power spectrogram')\n",
        "  plt.xlabel('time (s)')\n",
        "  plt.ylabel('Frequency (Hz)')\n",
        "  plt.colorbar(format=\"%+2.0f dB\")\n",
        "\n",
        "def plot_wave(signal, rate):  \n",
        "  displayWaveform(signal, rate)\n",
        "  displaySpectrum(signal, rate)\n",
        "  displaySpectrogram(signal, rate, fftlen=512)\n",
        "\n",
        "SIGNAL = S32h[-40*RATE:]\n",
        "plot_wave(SIGNAL, RATE)\n",
        "\n",
        "import IPython\n",
        "\n",
        "IPython.display.Audio(data=SIGNAL, rate=RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHVUZzXIE64f"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFaBo2s6K3Lk"
      },
      "source": [
        "### Data pre-treatment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wClPlpgoTGQ9"
      },
      "source": [
        "| signal| mat2wav | pick |\n",
        "| :---: | :---: | :---: |\n",
        "| S32h | 00:00-17:36 | 02:00-12:00 |\n",
        "| S41h | 01:21-14:03 | 02:00-12:00 |\n",
        "| S42h | 00:00-21:24 | 02:00-12:00 |\n",
        "| S43b | 01:01-37:31 | 02:00-12:00 14:00-24:00 26:00-36:00 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFeQLMRp2Qtx"
      },
      "outputs": [],
      "source": [
        "def cut_signal(signal_series):\n",
        "  sample_size = int(RATE/2)         # 4096\n",
        "  sample_step = int(sample_size/4)  # 512\n",
        "  sample_data = []\n",
        "  for i in range((len(signal_series)-sample_size) // sample_step):\n",
        "    sample_data.append(signal_series[i*sample_step : (i*sample_step+sample_size)])\n",
        "  sample_data = np.stack(sample_data)\n",
        "  sample_data = np.squeeze(sample_data)\n",
        "  # np.random.seed(42)\n",
        "  # np.random.shuffle(sample_data)  \n",
        "  return sample_data\n",
        "\n",
        "S32hCX = cut_signal(S32h[120*RATE:720*RATE])\n",
        "S41hCX = cut_signal(S41h[120*RATE:720*RATE])\n",
        "S42hCX = cut_signal(S42h[120*RATE:720*RATE])\n",
        "S43bCX1 = cut_signal(S43b[120*RATE:720*RATE])\n",
        "S43bCX2 = cut_signal(S43b[840*RATE:1440*RATE])\n",
        "S43bCX3 = cut_signal(S43b[1560*RATE:2160*RATE])\n",
        "\n",
        "S32hCY = np.repeat(0, len(S32hCX))\n",
        "S41hCY = np.repeat(0, len(S41hCX))\n",
        "S42hCY = np.repeat(0, len(S42hCX))\n",
        "S43bCY1 = np.repeat(1, len(S43bCX1))\n",
        "S43bCY2 = np.repeat(1, len(S43bCX2))\n",
        "S43bCY3 = np.repeat(1, len(S43bCX3))\n",
        "\n",
        "X_set = np.concatenate((S32hCX, S41hCX, S42hCX, S43bCX1, S43bCX2, S43bCX3), axis=0)\n",
        "X_set = X_set.reshape((X_set.shape[0], X_set.shape[1], 1))\n",
        "\n",
        "Y_set = np.concatenate((S32hCY, S41hCY, S42hCY, S43bCY1, S43bCY2, S43bCY3), axis=0)\n",
        "num_classes = len(np.unique(Y_set))\n",
        "Y_set = to_categorical(Y_set, num_classes=num_classes)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_set, Y_set, test_size=0.33, random_state=42)\n",
        "\n",
        "del S32hCX, S41hCX, S42hCX, S43bCX1, S43bCX2, S43bCX3, X_set\n",
        "del S32hCY, S41hCY, S42hCY, S43bCY1, S43bCY2, S43bCY3, Y_set\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzVAF5QwCFgM"
      },
      "source": [
        "### Model establishment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAWVESHNjlNW",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(64, 3, input_shape=x_train.shape[1:], padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(64, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Conv1D(128, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(128, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Conv1D(256, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(256, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(256, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV9UyRhCK9IS"
      },
      "source": [
        "### Complete & Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzdCmhMnBBZ3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy',\n",
        "                       keras.metrics.AUC(),\n",
        "                       keras.metrics.Precision(),\n",
        "                       keras.metrics.Recall()])\n",
        "\n",
        "callbacks = [\n",
        "             keras.callbacks.ModelCheckpoint(\"best_model.hdf5\",\n",
        "                                             monitor=\"loss\",\n",
        "                                             mode=\"min\",\n",
        "                                             save_best_only=True),\n",
        "             keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                           mode=\"min\",\n",
        "                                           verbose=1,\n",
        "                                           patience=10,\n",
        "                                           restore_best_weights=True), \n",
        "             keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                               factor=0.2,\n",
        "                                               patience=2,\n",
        "                                               min_lr=0.000001),\n",
        "            # keras.callbacks.TensorBoard(log_dir=os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_logs\"),\n",
        "            #                             histogram_freq=1,\n",
        "            #                             write_graph=True, \n",
        "            #                             write_images=True),\n",
        "            ]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_split=0.2, \n",
        "                    epochs=200, \n",
        "                    batch_size=64, \n",
        "                    callbacks=callbacks, \n",
        "                    shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3X-ecrEcpzO"
      },
      "source": [
        "### Show model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrZoVNFOb-Ys"
      },
      "outputs": [],
      "source": [
        "y_test_true = np.argmax(y_test, axis=1)\n",
        "y_test_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "test_loss, test_accuracy, test_auc, test_precision, test_recall = model.evaluate(x_test, y_test)\n",
        "\n",
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "precision = tp/(tp + fp)\n",
        "recall = tp/(tp + tn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRSyWBvs2Qtz"
      },
      "source": [
        "### Save model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6PvAJET2Qtz"
      },
      "outputs": [],
      "source": [
        "eval_dict = {\"y_test_true\":y_test_true, \"y_test_pred\":y_test_pred, \"test_loss\":test_loss, \"test_accuracy\":test_accuracy, \"test_auc\":test_auc, \"test_precision\":test_precision, \"test_recall\":test_recall, \"cm\":cm, \"cm_tn\":tn, \"cm_fp\":fp, \"cm_fn\":fn, \"cm_tp\":tp, \"cm_precision\":precision, \"cm_recall\":recall}\n",
        "\n",
        "model.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_model.hdf5\"))\n",
        "np.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_history.npy\"), history.history)\n",
        "np.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_evaluation.npy\"), eval_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKkPh_Tl2Qtz"
      },
      "source": [
        "### Load model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWjPRvbq2Qtz"
      },
      "outputs": [],
      "source": [
        "# from keras.models import load_model\n",
        "\n",
        "# model = load_model(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_model.hdf5\"))\n",
        "# hist = np.load(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_history.npy\"), allow_pickle=True).item()\n",
        "# eval_dict = np.load(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_evaluation.npy\"), allow_pickle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnGiiYP72Qt0"
      },
      "source": [
        "### Plot model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNbjUMfrBBb6"
      },
      "outputs": [],
      "source": [
        "def plot_history_metrics(history):\n",
        "  total_plots = len(history)\n",
        "  cols = total_plots // 2\n",
        "  rows = total_plots // cols\n",
        "  if total_plots % cols != 0:\n",
        "    rows += 1\n",
        "  pos = range(1, total_plots + 1)\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  for i, (key, value) in enumerate(history.items()):\n",
        "    plt.subplot(rows, cols, pos[i])\n",
        "    plt.plot(range(len(value)), value)\n",
        "    plt.title(str(key))\n",
        "  plt.savefig(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_evaluation.png\"))\n",
        " \n",
        "plot_history_metrics(history.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAQJZnnvpeT0"
      },
      "source": [
        "## Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJBJ9ZDJjr6M"
      },
      "source": [
        "### Data pre-treatment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUuoKno0HN9j"
      },
      "source": [
        "| signal| table | mat2wav |\n",
        "| :---: | :---: | :---: |\n",
        "| S11 | 10:59:18-11:01:50 | 00:00-02:32 |\n",
        "| S12 | 09:16:44-09:18:23 | 00:00-01:39 |\n",
        "| S13 | 09:21:37-09:23:05 | 00:00-01:28 |\n",
        "| S14 | 09:45:41-09:46:24 | 00:00-00:43 |\n",
        "| S15 | 09:49:43-09:50:15 | 00:00-00:32 |\n",
        "| S16 | 10:02:30-10:03:30 | 00:00-01:00 |\n",
        "| S17 | 10:27:57-10:29:26 | 00:00-01:29 |\n",
        "| S18 | 10:35:29-10:36:47 | 00:00-01:18 |\n",
        "| S19 | 10:40:35-10:41:28 | 00:00-00:53 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxhwGp3yQDYH",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "S11RX = S11[0:152*RATE]\n",
        "S12RX = S11[0:99*RATE]\n",
        "S13RX = S11[0:88*RATE]\n",
        "S14RX = S11[0:43*RATE]\n",
        "S15RX = S11[0:32*RATE]\n",
        "S16RX = S11[0:60*RATE]\n",
        "S17RX = S11[0:89*RATE]\n",
        "S18RX = S11[0:78*RATE]\n",
        "S19RX = S11[0:53*RATE]\n",
        "\n",
        "def load_table(table_path, time_start, time_end):\n",
        "  SIGNAL_pd = pd.read_excel(table_path)\n",
        "  display(SIGNAL_pd)\n",
        "  SIGNAL_arr = SIGNAL_pd.values[time_start : time_end,1:-1]\n",
        "  print(type(SIGNAL_arr), SIGNAL_arr.shape, len(SIGNAL_arr)-1, \"s\")\n",
        "  print(SIGNAL_arr)\n",
        "  return SIGNAL_arr\n",
        "\n",
        "S11RY = load_table(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/1_1.xls\"), 81, 82+152)\n",
        "S12RY = load_table(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/1_2.xls\"), 47, 51+96)\n",
        "S13RY = load_table(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/1_3.xls\"), 40, 41+88)\n",
        "S14RY = load_table(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/1_4.xls\"), 44, 45+43)\n",
        "S15RY = load_table(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/1_5.xls\"), 46, 47+32)\n",
        "S16RY = load_table(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/1_6.xls\"), 573, 574+60)\n",
        "S17RY = load_table(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/1_7.xls\"), 60, 61+89)\n",
        "S18RY = load_table(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/1_8.xls\"), 32, 33+78)\n",
        "S19RY = load_table(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/1_9.xls\"), 38, 39+53)\n",
        "\n",
        "def enlarge_value(array, length):\n",
        "  L = array.shape[0]\n",
        "  W = array.shape[1]\n",
        "  new_section = np.zeros([(L-1)*length, W-1])\n",
        "  for i in range(L - 1):   \n",
        "    new_second = np.zeros([length, W-1])\n",
        "    for j in range(W - 1):\n",
        "      start_value = float(array[i, j+1])\n",
        "      end_value = float(array[i+1, j+1])\n",
        "      new_second[:,j] = np.linspace(start_value, end_value, length + 2)[1:-1]  \n",
        "    new_section[i*length:(i+1)*length,:] = new_second\n",
        "  return new_section\n",
        "\n",
        "S11RY = enlarge_value(S11RY, RATE)\n",
        "S12RY = enlarge_value(S12RY, RATE)\n",
        "S13RY = enlarge_value(S13RY, RATE)\n",
        "S14RY = enlarge_value(S14RY, RATE)\n",
        "S15RY = enlarge_value(S15RY, RATE)\n",
        "S16RY = enlarge_value(S16RY, RATE)\n",
        "S17RY = enlarge_value(S17RY, RATE)\n",
        "S18RY = enlarge_value(S18RY, RATE)\n",
        "S19RY = enlarge_value(S19RY, RATE)\n",
        "\n",
        "def pick_value(signal, label):\n",
        "  sample_size = int(RATE/2)         # 4096\n",
        "  sample_step = int(sample_size/4)  # 512\n",
        "  sample_data = []\n",
        "  sample_idx = []\n",
        "  for i in range((len(signal)-sample_size) // sample_step):\n",
        "    sample_data.append(signal[i*sample_step : (i*sample_step+sample_size)])\n",
        "    sample_idx.append(i*sample_step + sample_size//2)\n",
        "  sample_data = np.stack(sample_data)\n",
        "  sample_data = np.squeeze(sample_data)\n",
        "  sample_label = label[sample_idx]\n",
        "  return sample_data, sample_label\n",
        "\n",
        "S11RX, S11RY = pick_value(S11RX, S11RY)\n",
        "S12RX, S12RY = pick_value(S12RX, S12RY)\n",
        "S13RX, S13RY = pick_value(S13RX, S13RY)\n",
        "S14RX, S14RY = pick_value(S14RX, S14RY)\n",
        "S15RX, S15RY = pick_value(S15RX, S15RY)\n",
        "S16RX, S16RY = pick_value(S16RX, S16RY)\n",
        "S17RX, S17RY = pick_value(S17RX, S17RY)\n",
        "S18RX, S18RY = pick_value(S18RX, S18RY)\n",
        "S19RX, S19RY = pick_value(S19RX, S19RY)\n",
        "\n",
        "X_set = np.concatenate((S11RX, S12RX, S13RX, S14RX, S15RX, S16RX, S17RX, S18RX, S19RX), axis=0)\n",
        "X_set = X_set.reshape((X_set.shape[0], X_set.shape[1], 1))\n",
        "\n",
        "Y_set = np.concatenate((S11RY, S12RY, S13RY, S14RY, S15RY, S16RY, S17RY, S18RY, S19RY), axis=0)\n",
        "num_targets = Y_set.shape[1]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_set, Y_set, test_size=0.33, random_state=42)\n",
        "\n",
        "del S32hRX, S41hRX, S42hRX, S43bRX, S32hRY, S41hRY, S42hRY, S43bRY, X_set, Y_set\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBrIMBV7G7SY"
      },
      "source": [
        "### Model establishment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_j3H1g7HBHs",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(64, 3, input_shape=x_train.shape[1:], padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(64, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Conv1D(128, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(128, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Conv1D(256, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(256, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(256, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(512, 3, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(4096))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_targets, activation='linear'))\n",
        "    return model\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ0MwcgcILMp"
      },
      "source": [
        "### Complete & Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6jYNXtxIM-v",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "callbacks = [\n",
        "             keras.callbacks.ModelCheckpoint(\"best_model.hdf5\",\n",
        "                                             monitor=\"loss\",\n",
        "                                             mode=\"min\",\n",
        "                                             save_best_only=True),\n",
        "             keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                           mode=\"min\",\n",
        "                                           verbose=1,\n",
        "                                           patience=10,\n",
        "                                           restore_best_weights=True), \n",
        "             keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                               factor=0.2,\n",
        "                                               patience=2,\n",
        "                                               min_lr=0.000001),\n",
        "            # keras.callbacks.TensorBoard(log_dir=os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_logs\"),\n",
        "            #                             histogram_freq=1,\n",
        "            #                             write_graph=True, \n",
        "            #                             write_images=True),\n",
        "            ]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_split=0.2, \n",
        "                    epochs=200, \n",
        "                    batch_size=64, \n",
        "                    callbacks=callbacks, \n",
        "                    shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnomC1kF2Qt1"
      },
      "source": [
        "### Show model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwe1VOp_2Qt1"
      },
      "outputs": [],
      "source": [
        "y_test_true = y_test\n",
        "y_test_pred = model.predict(x_test)\n",
        "test_loss = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlsB07lmcfgv"
      },
      "source": [
        "### Save model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0zhpsGYLCRn"
      },
      "outputs": [],
      "source": [
        "eval_dict = {\"y_test_true\":y_test_true, \"y_test_pred\":y_test_pred, \"test_loss\":test_loss}\n",
        "\n",
        "model.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/R_model.hdf5\"))\n",
        "np.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/R_history.npy\"), history.history)\n",
        "np.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/R_evaluation.npy\"), eval_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaMTBb5b2Qt2"
      },
      "source": [
        "### Load model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ-d3A-L2Qt2"
      },
      "outputs": [],
      "source": [
        "# from keras.models import load_model\n",
        "\n",
        "# model = load_model(\"/home/svu/e1097232/IDB_drilling_signal/outputs/R_model.hdf5\")\n",
        "# hist = np.load(\"/home/svu/e1097232/IDB_drilling_signal/outputs/R_history.npy\", allow_pickle=True)\n",
        "# eval_dict = np.load(\"/home/svu/e1097232/IDB_drilling_signal/outputs/R_evaluation.npy\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0DEo3fr2Qt-"
      },
      "source": [
        "### Plot model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IBsFW3V2Qt_"
      },
      "outputs": [],
      "source": [
        "# Plot Loss-Epoch\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train set', 'Test set'], loc='upper left')\n",
        "plt.savefig(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/R_loss.png\"))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iaMTBb5b2Qt2"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}