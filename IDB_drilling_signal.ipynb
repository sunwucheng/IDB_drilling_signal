{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QHVUZzXIE64f",
        "TpiifOj8A5-5",
        "u1RkpMgFLLsR",
        "7yF2rdDXjghc",
        "SV9UyRhCK9IS",
        "qZc9ctYii2-R",
        "A1r3bvw4LTq6",
        "pAQJZnnvpeT0",
        "yLVG3EhnFMmh",
        "P675rHgiXtsF",
        "nZQeTBkFdxGJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Materials"
      ],
      "metadata": {
        "id": "mA_-eAkuEnLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare environment"
      ],
      "metadata": {
        "id": "G6Dqfh0oC9d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone \"https://github.com/sunwucheng/IDB_drilling_signal.git\" /content/drive/MyDrive/IDB_drilling_signal\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "bKhi2VbCKlKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display signal data"
      ],
      "metadata": {
        "id": "0JJ3nLgyjX2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load signal data"
      ],
      "metadata": {
        "id": "N4rlRDFk7mas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io as scio\n",
        "\n",
        "def read_matFile(signal_path):\n",
        "  signal_file = scio.loadmat(signal_path)\n",
        "  signal_value = signal_file['samples']\n",
        "  signal_value = np.squeeze(signal_value)\n",
        "  return signal_value\n",
        "\n",
        "def read_wavFile(signal_path):\n",
        "  signal_rate, signal_value = scio.wavfile.read(signal_path)\n",
        "  return signal_value, signal_rate\n",
        "\n",
        "import librosa\n",
        "\n",
        "def read_soundFile(signal_path):\n",
        "  signal_value, signal_rate = librosa.load(signal_path, sr=None, mono=True, offset=0.0, duration=None)\n",
        "  return signal_value, signal_rate"
      ],
      "metadata": {
        "id": "jt6Ac0D3aTAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S32h = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/3-2h.mat\")\n",
        "S41h = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-1h.mat\")\n",
        "S42h = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-2h.mat\")\n",
        "S43b = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-3b.mat\")\n",
        "\n",
        "S41H, RATE = read_soundFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-1h.wav\")\n",
        "S42H, RATE = read_soundFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-2h.wav\")\n",
        "S43B1, RATE = read_soundFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-3b1.wav\")\n",
        "S43B2, RATE = read_soundFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-3b2.wav\")\n",
        "\n",
        "S11 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_1.mat\")\n",
        "S12 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_2.mat\")\n",
        "S13 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_3.mat\")\n",
        "S14 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_4.mat\")\n",
        "S15 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_5.mat\")\n",
        "S16 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_6.mat\")\n",
        "S17 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_7.mat\")\n",
        "S18 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_8.mat\")\n",
        "S19 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/1_9.mat\")\n",
        "\n",
        "S21 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_1.mat\")\n",
        "S22 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_2.mat\")\n",
        "S23 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_3.mat\")\n",
        "S24 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_4.mat\")\n",
        "S25 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_5.mat\")\n",
        "S26 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_6.mat\")\n",
        "S27 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_7.mat\")\n",
        "S28 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_8.mat\")\n",
        "S29 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/2_9.mat\")\n",
        "\n",
        "S31 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_1.mat\")\n",
        "S32 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_2.mat\")\n",
        "S33 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_3.mat\")\n",
        "S34 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_4.mat\")\n",
        "S35 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_5.mat\")\n",
        "S36 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_6.mat\")\n",
        "S37 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_7.mat\")\n",
        "S38 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_8.mat\")\n",
        "S39 = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment2/3_9.mat\")"
      ],
      "metadata": {
        "id": "y_yWjU4NvGWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RATE: \", RATE)\n",
        "print(\"---------------------------------------\")\n",
        "print(\"S32h : \", S32h.shape, len(S32h)/RATE, 's')\n",
        "print(\"S41h : \", S41h.shape, len(S41h)/RATE, 's')\n",
        "print(\"S42h : \", S42h.shape, len(S42h)/RATE, 's')\n",
        "print(\"S43b : \", S43b.shape, len(S43b)/RATE, 's')\n",
        "print(\"---------------------------------------\")\n",
        "print(\"S41H : \", S41H.shape, len(S41H)/RATE, 's')\n",
        "print(\"S42H : \", S42H.shape, len(S42H)/RATE, 's')\n",
        "print(\"S43B1: \", S43B1.shape, len(S43B1)/RATE, 's')\n",
        "print(\"S43B2: \", S43B2.shape, len(S43B2)/RATE, 's')\n",
        "print(\"---------------------------------------\")\n",
        "print(\"S11 : \", S11.shape, len(S11)/RATE, 's')\n",
        "print(\"S12 : \", S12.shape, len(S12)/RATE, 's')\n",
        "print(\"S13 : \", S13.shape, len(S13)/RATE, 's')\n",
        "print(\"S14 : \", S14.shape, len(S14)/RATE, 's')\n",
        "print(\"S15 : \", S15.shape, len(S15)/RATE, 's')\n",
        "print(\"S16 : \", S16.shape, len(S16)/RATE, 's')\n",
        "print(\"S17 : \", S17.shape, len(S17)/RATE, 's')\n",
        "print(\"S18 : \", S18.shape, len(S18)/RATE, 's')\n",
        "print(\"S19 : \", S19.shape, len(S19)/RATE, 's')\n",
        "print(\"---------------------------------------\")\n",
        "print(\"S21 : \", S21.shape, len(S21)/RATE, 's')\n",
        "print(\"S22 : \", S22.shape, len(S22)/RATE, 's')\n",
        "print(\"S23 : \", S23.shape, len(S23)/RATE, 's')\n",
        "print(\"S24 : \", S24.shape, len(S24)/RATE, 's')\n",
        "print(\"S25 : \", S25.shape, len(S25)/RATE, 's')\n",
        "print(\"S26 : \", S26.shape, len(S26)/RATE, 's')\n",
        "print(\"S27 : \", S27.shape, len(S27)/RATE, 's')\n",
        "print(\"S28 : \", S28.shape, len(S28)/RATE, 's')\n",
        "print(\"S29 : \", S29.shape, len(S29)/RATE, 's')\n",
        "print(\"---------------------------------------\")\n",
        "print(\"S31 : \", S31.shape, len(S31)/RATE, 's')\n",
        "print(\"S32 : \", S32.shape, len(S32)/RATE, 's')\n",
        "print(\"S33 : \", S33.shape, len(S33)/RATE, 's')\n",
        "print(\"S34 : \", S34.shape, len(S34)/RATE, 's')\n",
        "print(\"S35 : \", S35.shape, len(S35)/RATE, 's')\n",
        "print(\"S36 : \", S36.shape, len(S36)/RATE, 's')\n",
        "print(\"S37 : \", S37.shape, len(S37)/RATE, 's')\n",
        "print(\"S38 : \", S38.shape, len(S38)/RATE, 's')\n",
        "print(\"S39 : \", S39.shape, len(S39)/RATE, 's')"
      ],
      "metadata": {
        "id": "TmQmrA8iW6oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot signal data"
      ],
      "metadata": {
        "id": "aRDeP7mE7tsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def displayWaveform(signal, rate):\n",
        "  plt.figure(figsize=(20,6))\n",
        "  max = np.max(np.absolute(signal))*1.2\n",
        "  time = np.arange(0, len(SIGNAL)) / RATE\n",
        "  # plt.plot(time, signal)\n",
        "  librosa.display.waveshow(signal, sr=rate)\n",
        "  plt.title(\"Time domain waveform of speech signal\")\n",
        "  plt.xlabel(\"time (s)\")\n",
        "  plt.ylabel(\"amplitude\")\n",
        "  plt.xlim(0,len(SIGNAL)/RATE)\n",
        "  ymin, ymax = plt.ylim()\n",
        "  ylim = np.maximum(np.abs(ymin), np.abs(ymax))\n",
        "  plt.ylim(-ylim, ylim)\n",
        "\n",
        "def displaySpectrum(signal, rate):\n",
        "  plt.figure(figsize=(20,6)) \n",
        "  s = np.fft.fft(signal)\n",
        "  m = np.abs(s)\n",
        "  # f = np.linspace(0, rate, len(m))\n",
        "  # plt.plot(f, m)\n",
        "  n = len(signal)\n",
        "  f = np.fft.fftfreq(n, 1/rate)\n",
        "  plt.plot(f[:n//2],m[:n//2])\n",
        "  plt.title(\"Frequency domain spectral line of speech signal\")\n",
        "  plt.xlabel(\"Frequency (Hz)\")\n",
        "  plt.ylabel(\"amplitude\")\n",
        "  plt.xlim(0, rate//2)\n",
        "\n",
        "def displaySpectrogram(signal, rate, fftlen):    \n",
        "  plt.figure(figsize=(10,6))\n",
        "  # plt.specgram(signal, NFFT=fftlen, Fs=rate, noverlap=int(fftlen*0.25), window=np.hanning(fftlen))\n",
        "  signal_db = librosa.amplitude_to_db(np.abs(librosa.stft(signal, hop_length=int(fftlen*0.25))), ref=np.max) \n",
        "  librosa.display.specshow(signal_db, sr=rate, hop_length=int(fftlen*0.25), x_axis='time', y_axis='linear')\n",
        "  plt.title('Linear-frequency power spectrogram')\n",
        "  plt.xlabel('time (s)')\n",
        "  plt.ylabel('Frequency (Hz)')\n",
        "  plt.colorbar(format=\"%+2.0f dB\")\n",
        "\n",
        "def displayMelspectrogram(signal, rate):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  # melspectrogram = librosa.feature.melspectrogram(y=signal, sr=rate)\n",
        "  D = np.abs(librosa.stft(signal))**2\n",
        "  S = librosa.feature.melspectrogram(S=D, sr=rate)\n",
        "  S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "  img = librosa.display.specshow(S_dB, sr=rate, fmax=rate/2, x_axis='time', y_axis='mel') \n",
        "  plt.title('Mel-frequency spectrogram')\n",
        "  plt.colorbar(format='%+2.0f dB')\n",
        "\n",
        "def diaplayMFCC(signal, rate):\n",
        "  plt.figure(figsize=(8,6))\n",
        "  mfccs = librosa.feature.mfcc(y=signal, sr=rate)\n",
        "  librosa.display.specshow(mfccs, sr=rate, x_axis='time')\n",
        "\n",
        "def displayZCR(signal, rate):\n",
        "  plt.figure(figsize=(20, 6))\n",
        "  zcrs = librosa.feature.zero_crossing_rate(signal)  \n",
        "  plt.plot(zcrs[0])\n",
        "\n",
        "from sklearn import preprocessing\n",
        "def normalize(x, axis=0):\n",
        "    return preprocessing.minmax_scale(x, axis=axis)\n",
        "\n",
        "def displayCentroids(signal, rate):\n",
        "  # spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=rate)[0]\n",
        "  # frames = range(len(spectral_centroids))\n",
        "  # times = librosa.frames_to_time(frames)\n",
        "  # librosa.display.waveshow(signal, sr=rate, alpha=0.4)\n",
        "  # plt.plot(times, normalize(spectral_centroids), color='r')\n",
        "\n",
        "  cent = librosa.feature.spectral_centroid(y=signal, sr=rate) \n",
        "  S, phase = librosa.magphase(librosa.stft(y=signal))\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  librosa.feature.spectral_centroid(S=S)\n",
        "  freqs, times, D = librosa.reassigned_spectrogram(signal, fill_nan=True)\n",
        "  librosa.feature.spectral_centroid(S=np.abs(D), freq=freqs)\n",
        "  times = librosa.times_like(cent)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  ax[0].semilogy(times, cent[0], label='Spectral centroid')\n",
        "  ax[0].set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])\n",
        "  ax[0].legend()\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[1])\n",
        "  ax[1].plot(times, cent.T, label='Spectral centroid', color='w')\n",
        "  ax[1].set(title='log Power spectrogram')\n",
        "  ax[1].legend(loc='lower right')\n",
        "\n",
        "def displayBandwidth(signal, rate):\n",
        "  # spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(y=signal+0.01, sr=rate)[0]\n",
        "  # spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(y=signal+0.01, sr=rate, p=3)[0]\n",
        "  # spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(y=signal+0.01, sr=rate, p=4)[0]\n",
        "  # librosa.display.waveshow(signal, sr=rate, alpha=0.4)\n",
        "  # normal2 = preprocessing.minmax_scale(spectral_bandwidth_2, axis=0)\n",
        "  # normal3 = preprocessing.minmax_scale(spectral_bandwidth_3, axis=0)\n",
        "  # normal4 = preprocessing.minmax_scale(spectral_bandwidth_4, axis=0)\n",
        "  # spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=rate)[0]\n",
        "  # frames = range(len(spectral_centroids))\n",
        "  # times = librosa.frames_to_time(frames)\n",
        "  # plt.plot(times, normal2, color='r')\n",
        "  # plt.plot(times, normal3, color='g')\n",
        "  # plt.plot(times, normal4, color='y')\n",
        "  # plt.legend(('p = 2', 'p = 3', 'p = 4'))\n",
        "\n",
        "  spec_bw = librosa.feature.spectral_bandwidth(y=signal, sr=rate)\n",
        "  S, phase = librosa.magphase(librosa.stft(y=signal))\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  librosa.feature.spectral_bandwidth(S=S)\n",
        "  freqs, times, D = librosa.reassigned_spectrogram(signal, fill_nan=True)\n",
        "  librosa.feature.spectral_bandwidth(S=np.abs(D), freq=freqs)\n",
        "  times = librosa.times_like(spec_bw)\n",
        "  centroid = librosa.feature.spectral_centroid(S=S)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  ax[0].semilogy(times, spec_bw[0], label='Spectral bandwidth')\n",
        "  ax[0].set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])\n",
        "  ax[0].legend()\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  librosa.display.specshow(S_db, y_axis='log', x_axis='time', ax=ax[1])\n",
        "  ax[1].set(title='log Power spectrogram')\n",
        "  ax[1].fill_between(times, np.maximum(0, centroid[0] - spec_bw[0]), np.minimum(centroid[0] + spec_bw[0], rate/2), alpha=0.5, label='Centroid +- bandwidth')\n",
        "  ax[1].plot(times, centroid[0], label='Spectral centroid', color='w')\n",
        "  ax[1].legend(loc='lower right')\n",
        "\n",
        "def displayRolloff(signal, rate):\n",
        "  # spectral_rolloff = librosa.feature.spectral_rolloff(y=signal+0.01, sr=rate)[0]\n",
        "  # librosa.display.waveshow(signal, sr=rate, alpha=0.4)\n",
        "  # spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=rate)[0]\n",
        "  # frames = range(len(spectral_centroids))\n",
        "  # times = librosa.frames_to_time(frames)\n",
        "  # normals = preprocessing.minmax_scale(spectral_rolloff, axis=0)\n",
        "  # plt.plot(times, normals, color='r')\n",
        "\n",
        "  librosa.feature.spectral_rolloff(y=signal, sr=rate)\n",
        "  rolloff = librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.99)\n",
        "  rolloff_min = librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.01)\n",
        "  S, phase = librosa.magphase(librosa.stft(signal))\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  librosa.feature.spectral_rolloff(S=S, sr=rate)\n",
        "  librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.95)\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  librosa.display.specshow(S_db, y_axis='log', x_axis='time', ax=ax)\n",
        "  ax.plot(librosa.times_like(rolloff), rolloff[0], label='Roll-off frequency (0.99)')\n",
        "  ax.plot(librosa.times_like(rolloff), rolloff_min[0], color='w', label='Roll-off frequency (0.01)')\n",
        "  ax.legend(loc='lower right')\n",
        "  ax.set(title='log Power spectrogram')\n",
        "\n",
        "def displayChromastft(signal, rate, fftlen):\n",
        "  # plt.figure(figsize=(20, 6))\n",
        "  # chromagram = librosa.feature.chroma_stft(signal, sr=rate, hop_length=int(fftlen*0.25))\n",
        "  # librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=fftlen*0.25, cmap='coolwarm')\n",
        "\n",
        "  S = np.abs(librosa.stft(signal))\n",
        "  chroma = librosa.feature.chroma_stft(S=S, sr=rate)\n",
        "  S = np.abs(librosa.stft(signal, n_fft=fftlen))**2\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  chroma = librosa.feature.chroma_stft(S=S, sr=rate)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[0])\n",
        "  fig.colorbar(img, ax=[ax[0]])\n",
        "  ax[0].label_outer()\n",
        "  img = librosa.display.specshow(chroma, x_axis='time', y_axis='chroma', ax=ax[1])\n",
        "  fig.colorbar(img, ax=[ax[1]])\n",
        "\n",
        "def displayChromacqt(signal, rate, n_chroma, n_fft):\n",
        "  chroma_stft = librosa.feature.chroma_stft(y=signal, sr=rate, n_chroma=n_chroma, n_fft=n_fft)\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
        "  img1 = librosa.display.specshow(chroma_stft, x_axis='time', y_axis='chroma', ax=ax[0])\n",
        "  ax[0].set(title='chroma_stft')\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  img2 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[1])\n",
        "  ax[1].set(title='chroma_cqt')\n",
        "  fig.colorbar(img2, ax=ax)\n",
        "\n",
        "def displayChromacens(signal, rate):\n",
        "  chroma_cens = librosa.feature.chroma_cens(y=signal, sr=rate)\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
        "  img1 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[0])\n",
        "  ax[0].set(title='chroma_cq')\n",
        "  ax[0].label_outer()\n",
        "  img2 = librosa.display.specshow(chroma_cens, x_axis='time', y_axis='chroma', ax=ax[1])\n",
        "  ax[1].set(title='chroma_cens')\n",
        "  fig.colorbar(img1, ax=ax)\n",
        "\n",
        "def displayChromavqt(signal, rate, n_bins):\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate, n_chroma=n_bins)\n",
        "  chroma_vq = librosa.feature.chroma_vqt(y=signal, sr=rate, intervals='ji5', bins_per_octave=n_bins)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  img1 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[0], bins_per_octave=n_bins)\n",
        "  ax[0].set(ylabel='chroma_cqt')\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  img2 = librosa.display.specshow(chroma_vq, y_axis='chroma_fjs', x_axis='time', ax=ax[1], bins_per_octave=n_bins, intervals='ji5')\n",
        "  ax[1].set(ylabel='chroma_vqt')\n",
        "  fig.colorbar(img2, ax=ax)\n",
        "\n",
        "def plot_wave(signal, rate):  \n",
        "  displayWaveform(signal, rate)\n",
        "  displaySpectrum(signal, rate)\n",
        "  displaySpectrogram(signal, rate, fftlen=512)\n",
        "  displayMelspectrogram(signal, rate)\n",
        "  diaplayMFCC(signal, rate)\n",
        "  displayZCR(signal, rate)\n",
        "  displayCentroids(signal, rate)\n",
        "  displayBandwidth(signal, rate)\n",
        "  displayRolloff(signal, rate)\n",
        "  displayChromastft(signal, rate, fftlen=512)\n",
        "  displayChromacqt(signal, rate, n_chroma=12, n_fft=512)\n",
        "  displayChromacens(signal, rate)\n",
        "  displayChromavqt(signal, rate, n_bins=36)\n",
        "\n",
        "SIGNAL = S32h[0:120000]\n",
        "RATE = RATE\n",
        "plot_wave(SIGNAL, RATE)\n",
        "\n",
        "import IPython\n",
        "\n",
        "IPython.display.Audio(data=SIGNAL, rate=RATE)"
      ],
      "metadata": {
        "id": "laACxPu7uQWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to sound"
      ],
      "metadata": {
        "id": "yDFxEg0-HDPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import soundfile\n",
        "\n",
        "soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/S32h.wav\"), S32h, RATE)\n",
        "soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/S41h.wav\"), S41h, RATE)\n",
        "soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/S42h.wav\"), S42h, RATE)\n",
        "soundfile.write((\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/S43b.wav\"), S43b, RATE)"
      ],
      "metadata": {
        "id": "s8O6T2uMKNjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drilling table treatment"
      ],
      "metadata": {
        "id": "MJBJ9ZDJjr6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load parameter table"
      ],
      "metadata": {
        "id": "8ZU4vSh3jywY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# S31h 15:10:51-15:18:26 (15:10:00-15:19:22) [54:-56,1:-1] 455s\n",
        "# S32h 15:25:33-15:43:18 (15:25:00-15:43:22) [36:-4 ,1:-1] 1065s\n",
        "# S33b 15:48:20-16:13:46 (15:48:00-16:13:50) [23:-4 ,1:-1] 1526s\n",
        "# S41h 16:26:25-16:39:33 (16:26:00-16:39:50) [28:-17,1:-1] 788s\n",
        "# S42h 16:54:57-17:16:30 (16:54:30-17:16:50) [30:-20,1:-1] 1293s\n",
        "# S43b 17:24:00-18:00:24 (17:24:00-18:00:50) [3:-26 ,1:-1] 2184s\n",
        "\n",
        "# S31h_dict = {\"path\":\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/3-1h.xls\", \"index1\":54, \"index2\":-56}\n",
        "S32h_dict = {\"path\":\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/3-2h.xls\", \"index1\":36, \"index2\":-4}\n",
        "# S33b_dict = {\"path\":\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/3-3b.xls\", \"index1\":23, \"index2\":-4}\n",
        "S41h_dict = {\"path\":\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-1h.xls\", \"index1\":28, \"index2\":-17}\n",
        "S42h_dict = {\"path\":\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-2h.xls\", \"index1\":30, \"index2\":-20}\n",
        "S43b_dict = {\"path\":\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-3b.xls\", \"index1\":3, \"index2\":-26}\n",
        "\n",
        "\n",
        "# S11 10:58:07-11:01:48 (10:58:00-11:04:15)\n",
        "# S12 09:16:18-09:18:26 (09:16:00-09:18:50)\n",
        "# S13 09:21:30-09:23:03 (09:21:00-09:23:50)\n",
        "# S14 09:45:38-09:46:22 (09:45:00-09:46:50)\n",
        "# S15 09:49:44-09:50:13 (09:49:00-09:50:50)\n",
        "# S16 09:53:08- (09:53:00-)\n",
        "# ......"
      ],
      "metadata": {
        "id": "U8O8Y4-UjmUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_table(SIGNAL_dict):\n",
        "  SIGNAL_pd = pd.read_excel(SIGNAL_dict[\"path\"])\n",
        "  IPython.display.display(SIGNAL_pd)\n",
        "  SIGNAL_arr = SIGNAL_pd.values[SIGNAL_dict[\"index1\"]:SIGNAL_dict[\"index2\"],1:-1]\n",
        "  print(type(SIGNAL_arr), SIGNAL_arr.shape, len(SIGNAL_arr)-1, \"s\")\n",
        "  print(SIGNAL_arr)\n",
        "  return SIGNAL_arr\n",
        "\n",
        "S32h_arr = load_table(S32h_dict)\n",
        "S41h_arr = load_table(S41h_dict)\n",
        "S42h_arr = load_table(S42h_dict)\n",
        "S43b_arr = load_table(S43b_dict)"
      ],
      "metadata": {
        "id": "dP80s_nDnE8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enlarge parameter data"
      ],
      "metadata": {
        "id": "EhqzcDzbkRYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enlarge_value(array, length):\n",
        "\n",
        "  L = array.shape[0]\n",
        "  W = array.shape[1]\n",
        "  \n",
        "  new_section = np.zeros([(L-1)*length, W-1])\n",
        "  for i in range(L - 1):   \n",
        "\n",
        "    new_second = np.zeros([length, W-1])\n",
        "    for j in range(W - 1):\n",
        "\n",
        "      start_value = float(array[i, j+1])\n",
        "      end_value = float(array[i+1, j+1])\n",
        "\n",
        "      new_second[:,j] = np.linspace(start_value, end_value, length + 2)[1:-1]\n",
        "       \n",
        "    new_section[i*length:(i+1)*length,:] = new_second\n",
        "  \n",
        "  return new_section\n",
        "\n",
        "ARRAY = S41h_arr\n",
        "LENGTH = RATE\n",
        "ARRAY_new = enlarge_value(ARRAY, LENGTH)\n",
        "print(ARRAY_new)\n",
        "print(ARRAY_new.shape)"
      ],
      "metadata": {
        "id": "NX86geiaj2FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Signal dataset establishment"
      ],
      "metadata": {
        "id": "KkBGp9Tx-BV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(signal_value):\n",
        "\n",
        "  sample_size = 1200\n",
        "  sample_step = 600\n",
        "  sample_data = []\n",
        "\n",
        "  for i in range((len(signal_value)-sample_size) // sample_step):\n",
        "    sample_data.append(signal_value[i*sample_step : (i*sample_step+sample_size)])\n",
        "\n",
        "  sample_data = np.stack(sample_data)\n",
        "  sample_data = np.squeeze(sample_data)\n",
        "\n",
        "  # np.random.seed(42)\n",
        "  # np.random.shuffle(sample_data)\n",
        "  \n",
        "  return sample_data\n",
        "\n",
        "S41hS = make_dataset(S41h)"
      ],
      "metadata": {
        "id": "exafUe2G9C7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "X_set = np.concatenate((S41hS, S42hS, S43b1S, S43b2S), axis=0)\n",
        "Y_set = np.concatenate((np.full(len(S41hS)+len(S42hS), 0), np.full(len(S43b1S)+len(S43b2S), 1)), axis=0)\n",
        "num_classes = len(np.unique(Y_set))\n",
        "X_set = X_set.reshape((X_set.shape[0], X_set.shape[1], 1))\n",
        "Y_set = to_categorical(Y_set, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "H8hSOO6B_6cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_set, Y_set, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "Jt626tuZLI_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification model"
      ],
      "metadata": {
        "id": "QHVUZzXIE64f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "vsP4RTOrqK9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1D pure FC model"
      ],
      "metadata": {
        "id": "TpiifOj8A5-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Flatten()(input_layer)\n",
        "  x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(x_train.shape[1], activation=\"relu\")(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "# keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "9cQ2v297BBXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1D pure Conv model"
      ],
      "metadata": {
        "id": "u1RkpMgFLLsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "# keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "yMU-Vjz3DRNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1D mix Conv model"
      ],
      "metadata": {
        "id": "7yF2rdDXjghc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = layers.Conv1D(filters=32, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(input_layer)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv1D(filters=64, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv1D(filters=128, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv1D(filters=256, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv1D(filters=512, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv1D(filters=1024, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(2048, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(1024, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  output_layer = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "# keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "bAWVESHNjlNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile&Training"
      ],
      "metadata": {
        "id": "SV9UyRhCK9IS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy',\n",
        "                       keras.metrics.AUC(),\n",
        "                       keras.metrics.Precision(),\n",
        "                       keras.metrics.Recall()])\n",
        "\n",
        "callbacks = [\n",
        "            # keras.callbacks.ModelCheckpoint(\"best_model.h5\",\n",
        "            #                                  monitor=\"loss\",\n",
        "            #                                  mode=\"min\",\n",
        "            #                                  save_best_only=True),\n",
        "             keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                           mode=\"min\",\n",
        "                                           patience=10,\n",
        "                                           restore_best_weights=True),\n",
        "             keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
        "                                               factor=0.2, \n",
        "                                               patience=2,\n",
        "                                               min_lr=0.000001),\n",
        "             keras.callbacks.TensorBoard(log_dir='./output/logs',\n",
        "                                         histogram_freq=1,\n",
        "                                         write_graph=True, \n",
        "                                         write_images=True)]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_split=0.2, \n",
        "                    epochs=300, \n",
        "                    batch_size=64, \n",
        "                    callbacks=callbacks, \n",
        "                    shuffle=True)\n",
        "\n",
        "model.save(os.path.join(PROJECT_path, \"output\", \"model.h5\"))\n",
        "np.save('output/history.npy', history.history, allow_pickle=True)\n",
        "# hist = np.load('history.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "OzdCmhMnBBZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot history metrics"
      ],
      "metadata": {
        "id": "qZc9ctYii2-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history_metrics(history):\n",
        "  \n",
        "  total_plots = len(history.history)\n",
        "  cols = total_plots // 2\n",
        "  rows = total_plots // cols\n",
        "\n",
        "  if total_plots % cols != 0:\n",
        "    rows += 1\n",
        "\n",
        "  pos = range(1, total_plots + 1)\n",
        "\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  for i, (key, value) in enumerate(history.history.items()):\n",
        "    plt.subplot(rows, cols, pos[i])\n",
        "    plt.plot(range(len(value)), value)\n",
        "    plt.title(str(key))\n",
        "\n",
        "plot_history_metrics(history)\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir \"/content/drive/MyDrive/IDB_drilling_signal/output/logs\""
      ],
      "metadata": {
        "id": "eNbjUMfrBBb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test-set evaluation"
      ],
      "metadata": {
        "id": "A1r3bvw4LTq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy, test_auc, test_precision, tes_recall = model.evaluate(x_test, y_test)\n",
        "print(\"Test loss\", test_loss)\n",
        "print(\"Test accuracy\", test_accuracy)\n",
        "print(\"test_auc\", test_auc) \n",
        "print(\"test_precision\", test_precision) \n",
        "print(\"tesrecall\", tes_recall)"
      ],
      "metadata": {
        "id": "pSULLYM8dWk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def show_cm(y_true, y_pred):\n",
        "\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "  plt.xticks([0,1])\n",
        "  plt.yticks([0,1])\n",
        "  plt.xlabel(\"Predict\")\n",
        "  plt.ylabel(\"True\")\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "  plt.text(x=0-0.1, y=0, s=\"TP:\"+str(tp), color='black')\n",
        "  plt.text(x=1-0.1, y=0, s=\"FN:\"+str(fn), color='black')\n",
        "  plt.text(x=0-0.1, y=1, s=\"FP:\"+str(fp), color='black')\n",
        "  plt.text(x=1-0.1, y=1, s=\"TN:\"+str(tn), >color='black')\n",
        "  precision = tp/(tp + fp)\n",
        "  recall = tp/(tp + tn)\n",
        "  print(\"precision:\", precision)\n",
        "  print(\"recall:\", recall)\n",
        "  plt.show()\n",
        "\n",
        "show_cm(y_test, y_pred)"
      ],
      "metadata": {
        "id": "LGUbJBchdz0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression model"
      ],
      "metadata": {
        "id": "pAQJZnnvpeT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transpose autoencoder"
      ],
      "metadata": {
        "id": "yLVG3EhnFMmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.Conv1D(filters=64, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Dropout(rate=0.2)(x)\n",
        "  x = keras.Conv1D(filters=32, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Dropout(rate=0.2)(x)\n",
        "  x = keras.Conv1D(filters=16, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Dropout(rate=0.2)(x)\n",
        "\n",
        "  x = keras.Conv1DTranspose(filters=16, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Conv1DTranspose(filters=32, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Conv1DTranspose(filters=64, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Conv1DTranspose(filters=1, kernel_size=6, padding=\"same\")(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "# keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "XJxHVtR69Qj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)]\n",
        "\n",
        "history = model.fit(x_train, x_train,\n",
        "                    epochs=300,\n",
        "                    batch_size=64,                    \n",
        "                    validation_split=0.2,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "ybM42yrhGqwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get train MAE loss.\n",
        "x_train_pred = model.predict(x_train)\n",
        "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
        "\n",
        "plt.hist(train_mae_loss, bins=50)\n",
        "plt.xlabel(\"Train MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "# Get reconstruction loss threshold.\n",
        "threshold = np.max(train_mae_loss)\n",
        "print(\"Reconstruction error threshold: \", threshold)"
      ],
      "metadata": {
        "id": "ar7a0PP1Gq1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking how the first sequence is learnt\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.plot(x_train[0])\n",
        "plt.plot(x_train_pred[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yrWp0lUEGq3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get test MAE loss.\n",
        "x_test_pred = model.predict(x_test)\n",
        "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
        "test_mae_loss = test_mae_loss.reshape((-1))\n",
        "\n",
        "plt.hist(test_mae_loss, bins=50)\n",
        "plt.xlabel(\"test MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "# Detect all the samples which are anomalies.\n",
        "anomalies = test_mae_loss > threshold\n",
        "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
        "print(\"Indices of anomaly samples: \", np.where(anomalies))"
      ],
      "metadata": {
        "id": "BNEykUEdGq5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-made autoencoder-2D"
      ],
      "metadata": {
        "id": "P675rHgiXtsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "input_size = 1024\n",
        "hidden_size = 256\n",
        "code_size = 64\n",
        "latent_dim = 2"
      ],
      "metadata": {
        "id": "2f2YevYNV6SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Input(shape=(input_size,))\n",
        "h1 = Dense(hidden_size, activation='relu')(x)\n",
        "h2 = Dense(code_size, activation='relu')(h1)\n",
        "l = Dense(latent_dim, activation='relu')(h2)\n",
        "h3 = Dense(code_size, activation='relu')(l)\n",
        "h4 = Dense(hidden_size, activation='relu')(h3)\n",
        "r = Dense(input_size, activation='sigmoid')(h4)"
      ],
      "metadata": {
        "id": "w7cLFMexV6Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Model(x, r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "1WVEZFzLV6Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "plt.figure()\n",
        "plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], c=Y_train)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C-iawz8ncfYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, \n",
        "                          batch_size=batch_size, \n",
        "                          epochs=epochs, \n",
        "                          verbose=1, \n",
        "                          validation_data=(X_test, X_test),\n",
        "                          )"
      ],
      "metadata": {
        "id": "t2SBTshFV6ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "plt.figure()\n",
        "plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], c=Y_train)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HFH2Exp5V6dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-made autoencoder-3D"
      ],
      "metadata": {
        "id": "nZQeTBkFdxGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "input_size = 1024\n",
        "hidden_size = 256\n",
        "code_size = 64\n",
        "latent_dim = 3"
      ],
      "metadata": {
        "id": "zrwffnUUdxGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Input(shape=(input_size,))\n",
        "h1 = Dense(hidden_size, activation='relu')(x)\n",
        "h2 = Dense(code_size, activation='relu')(h1)\n",
        "l = Dense(latent_dim, activation='relu')(h2)\n",
        "h3 = Dense(code_size, activation='relu')(l)\n",
        "h4 = Dense(hidden_size, activation='relu')(h3)\n",
        "r = Dense(input_size, activation='sigmoid')(h4)"
      ],
      "metadata": {
        "id": "FSlj0KThdxGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Model(x, r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "wD0qqHskdxGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder = Model(x, l)\n",
        "# X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "# plt.figure()\n",
        "# plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], X_train_encoded[:, 2], c=Y_train)\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "\n",
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "ax.scatter(X_train_encoded[:,0], X_train_encoded[:,1], X_train_encoded[:,2], c=Y_train)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pS_j5KvFdxGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, \n",
        "                          batch_size=batch_size, \n",
        "                          epochs=epochs, \n",
        "                          verbose=1, \n",
        "                          validation_data=(X_test, X_test),\n",
        "                          )"
      ],
      "metadata": {
        "id": "MdAjjqAddxGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder = Model(x, l)\n",
        "# X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "# plt.figure()\n",
        "# plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], X_train_encoded[:, 2], c=Y_train)\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "\n",
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "ax.scatter(X_train_encoded[:,0], X_train_encoded[:,1], X_train_encoded[:,2], c=Y_train)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nBTz1HVSdxGX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}