{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA_-eAkuEnLC"
   },
   "source": [
    "# IDB_drilling_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6Dqfh0oC9d7"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.io as scio\n",
    "import seaborn as sns\n",
    "import time\n",
    "import visualkeras\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, Concatenate, Conv1D, Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling1D, GlobalAveragePooling2D, Input, MaxPooling1D, MaxPooling2D\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from pyts.image import RecurrencePlot, MarkovTransitionField, GramianAngularField\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "HOST_path = \"/hpctmp/e1097232\"\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def nameof(var):\n",
    "    for name, value in globals().items():\n",
    "        if value is var:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4rlRDFk7mas"
   },
   "source": [
    "## Load signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jt6Ac0D3aTAx"
   },
   "outputs": [],
   "source": [
    "RATE = 8192\n",
    "\n",
    "def read_matFile(signal_path):\n",
    "    signal_file = scio.loadmat(signal_path)\n",
    "    signal_value = signal_file['samples']\n",
    "    signal_value = np.squeeze(signal_value)\n",
    "    print(\"signal_shape:\", signal_value.shape, \"sampling_rate:\", RATE, \"time:\", len(signal_value)/RATE, \"s\")\n",
    "    max_value = np.max(np.abs(signal_value))\n",
    "    signal_value_normalized = signal_value / max_value\n",
    "    return signal_value_normalized\n",
    "\n",
    "def read_allFile(signal_path):\n",
    "    signal_value, signal_rate = librosa.load(signal_path, sr=None, mono=True, offset=0.0, duration=None)\n",
    "    print(\"signal_shape:\", signal_value.shape, \"sampling_rate:\", signal_rate, \"time:\", len(signal_value)/signal_rate, \"s\")\n",
    "    if signal_rate != RATE:\n",
    "        signal_value = librosa.resample(signal_value, orig_sr=signal_rate, target_sr=RATE)\n",
    "    max_value = np.max(np.abs(signal_value))\n",
    "    signal_value_normalized = signal_value / max_value\n",
    "    return signal_value_normalized\n",
    "\n",
    "# granite\n",
    "G32h = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment1/matFile/3-2h.mat\"))\n",
    "G41h = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment1/matFile/4-1h.mat\"))\n",
    "G42h = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment1/matFile/4-2h.mat\"))\n",
    "G43b = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment1/matFile/4-3b.mat\"))\n",
    "# sandstone\n",
    "S11 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/1-1.mat\"))\n",
    "S12 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/1-2.mat\"))\n",
    "S13 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/1-3.mat\"))\n",
    "S14 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/1-4.mat\"))\n",
    "S21 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/2-1.mat\"))\n",
    "S22 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/2-2.mat\"))\n",
    "S23 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/2-3.mat\"))\n",
    "S31 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/3-1.mat\"))\n",
    "S32 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/3-2.mat\"))\n",
    "S33 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/3-3.mat\"))\n",
    "S41 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/4-1.mat\"))\n",
    "S42 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/4-2.mat\"))\n",
    "S43 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/4-3.mat\"))\n",
    "S51 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/5-1.mat\"))\n",
    "S52 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/5-2.mat\"))\n",
    "S53 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/5-3.mat\"))\n",
    "S54 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/5-4.mat\"))\n",
    "S61 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/6-1.mat\"))\n",
    "S62 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/6-2.mat\"))\n",
    "S63 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/6-3.mat\"))\n",
    "S71 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/7-1.mat\"))\n",
    "S72 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/7-2.mat\"))\n",
    "S73 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/7-3.mat\"))\n",
    "S74 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/7-4.mat\"))\n",
    "S81 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/8-1.mat\"))\n",
    "S82 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/8-2.mat\"))\n",
    "S83 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/8-3.mat\"))\n",
    "S91 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/9-1.mat\"))\n",
    "S92 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/9-2.mat\"))\n",
    "S93 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/9-3.mat\"))\n",
    "S94 = read_matFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment2/matFile/9-4.mat\"))\n",
    "# basalt\n",
    "B11 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/1-1.wav\"))\n",
    "B12 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/1-2.wav\"))\n",
    "B13 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/1-3.wav\"))\n",
    "B21 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/2-1.wav\"))\n",
    "B22 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/2-2.wav\"))\n",
    "B23 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/2-3.wav\"))\n",
    "B31 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/3-1.wav\"))\n",
    "B32 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/3-2.wav\"))\n",
    "B33 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/3-3.wav\"))\n",
    "B41 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/4-1.wav\"))\n",
    "B42 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/4-2.wav\"))\n",
    "B43 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/4-3.wav\"))\n",
    "B51 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/5-1.wav\"))\n",
    "B52 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/5-2.wav\"))\n",
    "B53 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/5-3.wav\"))\n",
    "B54 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/5-4.wav\"))\n",
    "B61 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/6-1.wav\"))\n",
    "B62 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/6-2.wav\"))\n",
    "B63 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/6-3.wav\"))\n",
    "B71 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/7-1.wav\"))\n",
    "B72 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/7-2.wav\"))\n",
    "B73 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/7-3.wav\"))\n",
    "B81 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/8-1.wav\"))\n",
    "B82 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/8-2.wav\"))\n",
    "B83 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/8-3.wav\"))\n",
    "B91 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/9-1.wav\"))\n",
    "B92 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/9-2.wav\"))\n",
    "B93 = read_allFile(os.path.join(HOST_path, \"IDB_drilling_signal/Rock_drilling_signal/experiment3/waveFile/9-3.wav\"))\n",
    "print(\"------------------------------------\")\n",
    "print(\"All signal normalized with sr = 8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def displayWaveform(signal, rate):\n",
    "  plt.figure(figsize=(20,6))\n",
    "  max = np.max(np.absolute(signal))*1.2\n",
    "  time = np.arange(0, len(SIGNAL)) / RATE\n",
    "  plt.plot(time, signal)\n",
    "  plt.title(\"Time domain waveform of speech signal\")\n",
    "  plt.xlabel(\"time (s)\")\n",
    "  plt.ylabel(\"amplitude\")\n",
    "  plt.xlim(0,len(SIGNAL)/RATE)\n",
    "  ymin, ymax = plt.ylim()\n",
    "  ylim = np.maximum(np.abs(ymin), np.abs(ymax))\n",
    "  plt.ylim(-ylim, ylim)\n",
    "\n",
    "def displaySpectrum(signal, rate):\n",
    "  plt.figure(figsize=(20,6)) \n",
    "  s = np.fft.fft(signal)\n",
    "  m = np.abs(s)\n",
    "  n = len(signal)\n",
    "  f = np.fft.fftfreq(n, 1/rate)\n",
    "  plt.plot(f[:n//2],m[:n//2])\n",
    "  plt.title(\"Frequency domain spectral line of speech signal\")\n",
    "  plt.xlabel(\"Frequency (Hz)\")\n",
    "  plt.ylabel(\"amplitude\")\n",
    "  plt.xlim(0, rate//2)\n",
    "\n",
    "def displaySpectrogram(signal, rate, fftlen):    \n",
    "  plt.figure(figsize=(8,6))\n",
    "  plt.specgram(signal, NFFT=fftlen, Fs=rate, noverlap=int(fftlen*0.25), window=np.hanning(fftlen))\n",
    "  plt.title('Linear-frequency power spectrogram')\n",
    "  plt.xlabel('time (s)')\n",
    "  plt.ylabel('Frequency (Hz)')\n",
    "  plt.colorbar(format=\"%+2.0f dB\")\n",
    "    \n",
    "def displayMelspectrogram(signal, rate):\n",
    "  plt.figure(figsize=(8,6))\n",
    "  # melspectrogram = librosa.feature.melspectrogram(y=signal, sr=rate)\n",
    "  D = np.abs(librosa.stft(signal))**2\n",
    "  S = librosa.feature.melspectrogram(S=D, sr=rate)\n",
    "  S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "  img = librosa.display.specshow(S_dB, sr=rate, fmax=rate/2, x_axis='time', y_axis='mel') \n",
    "  plt.title('Mel-frequency spectrogram')\n",
    "  plt.colorbar(format='%+2.0f dB')\n",
    "\n",
    "def diaplayMFCC(signal, rate):\n",
    "  plt.figure(figsize=(8,6))\n",
    "  mfccs = librosa.feature.mfcc(y=signal, sr=rate)\n",
    "  librosa.display.specshow(mfccs, sr=rate, x_axis='time')\n",
    "  plt.colorbar(format='%+2.0f dB')\n",
    "\n",
    "def displayZCR(signal, rate):\n",
    "  plt.figure(figsize=(8,3))\n",
    "  zcrs = librosa.feature.zero_crossing_rate(signal)  \n",
    "  plt.plot(zcrs[0])\n",
    "\n",
    "def normalize(x, axis=0):\n",
    "    return preprocessing.minmax_scale(x, axis=axis)\n",
    "\n",
    "def displayCentroids(signal, rate):\n",
    "  cent = librosa.feature.spectral_centroid(y=signal, sr=rate) \n",
    "  S, phase = librosa.magphase(librosa.stft(y=signal))\n",
    "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
    "  librosa.feature.spectral_centroid(S=S)\n",
    "  freqs, times, D = librosa.reassigned_spectrogram(signal, fill_nan=True)\n",
    "  librosa.feature.spectral_centroid(S=np.abs(D), freq=freqs)\n",
    "  times = librosa.times_like(cent)\n",
    "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "  ax[0].semilogy(times, cent[0], label='Spectral centroid')\n",
    "  ax[0].set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])\n",
    "  ax[0].legend()\n",
    "  ax[0].label_outer()\n",
    "  librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[1])\n",
    "  ax[1].plot(times, cent.T, label='Spectral centroid', color='w')\n",
    "  ax[1].set(title='log Power spectrogram')\n",
    "  ax[1].legend(loc='lower right')\n",
    "\n",
    "def displayBandwidth(signal, rate):\n",
    "  spec_bw = librosa.feature.spectral_bandwidth(y=signal, sr=rate)\n",
    "  S, phase = librosa.magphase(librosa.stft(y=signal))\n",
    "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
    "  librosa.feature.spectral_bandwidth(S=S)\n",
    "  freqs, times, D = librosa.reassigned_spectrogram(signal, fill_nan=True)\n",
    "  librosa.feature.spectral_bandwidth(S=np.abs(D), freq=freqs)\n",
    "  times = librosa.times_like(spec_bw)\n",
    "  centroid = librosa.feature.spectral_centroid(S=S)\n",
    "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "  ax[0].semilogy(times, spec_bw[0], label='Spectral bandwidth')\n",
    "  ax[0].set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])\n",
    "  ax[0].legend()\n",
    "  ax[0].label_outer()\n",
    "  librosa.display.specshow(S_db, y_axis='log', x_axis='time', ax=ax[1])\n",
    "  ax[1].set(title='log Power spectrogram')\n",
    "  ax[1].fill_between(times, np.maximum(0, centroid[0] - spec_bw[0]), np.minimum(centroid[0] + spec_bw[0], rate/2), alpha=0.5, label='Centroid +- bandwidth')\n",
    "  ax[1].plot(times, centroid[0], label='Spectral centroid', color='w')\n",
    "  ax[1].legend(loc='lower right')\n",
    "\n",
    "def displayRolloff(signal, rate):\n",
    "  librosa.feature.spectral_rolloff(y=signal, sr=rate)\n",
    "  rolloff = librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.99)\n",
    "  rolloff_min = librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.01)\n",
    "  S, phase = librosa.magphase(librosa.stft(signal))\n",
    "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
    "  librosa.feature.spectral_rolloff(S=S, sr=rate)\n",
    "  librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.95)\n",
    "  fig, ax = plt.subplots()\n",
    "  librosa.display.specshow(S_db, y_axis='log', x_axis='time', ax=ax)\n",
    "  ax.plot(librosa.times_like(rolloff), rolloff[0], label='Roll-off frequency (0.99)')\n",
    "  ax.plot(librosa.times_like(rolloff), rolloff_min[0], color='w', label='Roll-off frequency (0.01)')\n",
    "  ax.legend(loc='lower right')\n",
    "  ax.set(title='log Power spectrogram')\n",
    "\n",
    "def displayChromastft(signal, rate, fftlen):\n",
    "  S = np.abs(librosa.stft(signal))\n",
    "  chroma = librosa.feature.chroma_stft(S=S, sr=rate)\n",
    "  S = np.abs(librosa.stft(signal, n_fft=fftlen))**2\n",
    "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
    "  chroma = librosa.feature.chroma_stft(S=S, sr=rate)\n",
    "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "  img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[0])\n",
    "  fig.colorbar(img, ax=[ax[0]])\n",
    "  ax[0].label_outer()\n",
    "  img = librosa.display.specshow(chroma, x_axis='time', y_axis='chroma', ax=ax[1])\n",
    "  fig.colorbar(img, ax=[ax[1]])\n",
    "\n",
    "def displayChromacqt(signal, rate, n_chroma, n_fft):\n",
    "  chroma_stft = librosa.feature.chroma_stft(y=signal, sr=rate, n_chroma=n_chroma, n_fft=n_fft)\n",
    "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate)\n",
    "  fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
    "  img1 = librosa.display.specshow(chroma_stft, x_axis='time', y_axis='chroma', ax=ax[0])\n",
    "  ax[0].set(title='chroma_stft')\n",
    "  ax[0].label_outer()\n",
    "  img2 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[1])\n",
    "  ax[1].set(title='chroma_cqt')\n",
    "  fig.colorbar(img2, ax=ax)\n",
    "\n",
    "def displayChromacens(signal, rate):\n",
    "  chroma_cens = librosa.feature.chroma_cens(y=signal, sr=rate)\n",
    "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate)\n",
    "  fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
    "  img1 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[0])\n",
    "  ax[0].set(title='chroma_cq')\n",
    "  ax[0].label_outer()\n",
    "  img2 = librosa.display.specshow(chroma_cens, x_axis='time', y_axis='chroma', ax=ax[1])\n",
    "  ax[1].set(title='chroma_cens')\n",
    "  fig.colorbar(img1, ax=ax)\n",
    "\n",
    "def displayChromavqt(signal, rate, n_bins):\n",
    "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate, n_chroma=n_bins)\n",
    "  chroma_vq = librosa.feature.chroma_vqt(y=signal, sr=rate, intervals='ji5', bins_per_octave=n_bins)\n",
    "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "  img1 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[0], bins_per_octave=n_bins)\n",
    "  ax[0].set(ylabel='chroma_cqt')\n",
    "  ax[0].label_outer()\n",
    "  img2 = librosa.display.specshow(chroma_vq, y_axis='chroma_fjs', x_axis='time', ax=ax[1], bins_per_octave=n_bins, intervals='ji5')\n",
    "  ax[1].set(ylabel='chroma_vqt')\n",
    "  fig.colorbar(img2, ax=ax)\n",
    "\n",
    "def plot_wave(signal, rate):  \n",
    "  displayWaveform(signal, rate)\n",
    "  displaySpectrum(signal, rate)\n",
    "  displaySpectrogram(signal, rate, fftlen=512)\n",
    "  displayMelspectrogram(signal, rate)\n",
    "  diaplayMFCC(signal, rate)\n",
    "#   displayZCR(signal, rate)\n",
    "#   displayCentroids(signal, rate)\n",
    "#   displayBandwidth(signal, rate)\n",
    "#   displayRolloff(signal, rate)\n",
    "#   displayChromastft(signal, rate, fftlen=512)\n",
    "#   displayChromacqt(signal, rate, n_chroma=12, n_fft=512)\n",
    "#   displayChromacens(signal, rate)\n",
    "#   displayChromavqt(signal, rate, n_bins=24)\n",
    "\n",
    "SIGNAL = G32h[0:RATE]\n",
    "plot_wave(SIGNAL, RATE)\n",
    "IPython.display.Audio(data=SIGNAL, rate=RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G32h = G32h[0:1056*RATE]\n",
    "G41h = G41h[120*RATE:840*RATE]\n",
    "G42h = G42h[0:1260*RATE]\n",
    "G43b = G43b[100*RATE:2240*RATE]\n",
    "\n",
    "S11 = S11[0:150*RATE]\n",
    "S12 = S12[210*RATE:416*RATE]\n",
    "S13 = S13[140*RATE:374*RATE]\n",
    "S14 = S14[2*RATE:136*RATE]\n",
    "S21 = S21[0:103*RATE]\n",
    "S22 = S22[0:156*RATE]\n",
    "S23 = S23[42*RATE:126*RATE]\n",
    "S31 = S31[0:86*RATE]\n",
    "S32 = S32[76*RATE:213*RATE]\n",
    "S33 = S33[33*RATE:130*RATE]\n",
    "S41 = S41[0:41*RATE]\n",
    "S42 = S42[100*RATE:123*RATE]\n",
    "S43 = S43[115*RATE:135*RATE]\n",
    "S51 = S51[3*RATE:28*RATE]\n",
    "S52 = S52[103*RATE:126*RATE]\n",
    "S53 = S53[126*RATE:153*RATE]\n",
    "S54 = S54[157*RATE:181*RATE]\n",
    "S61 = S61[40*RATE:57*RATE]\n",
    "S62 = S62[128*RATE:150*RATE]\n",
    "S63 = S63[35*RATE:51*RATE]\n",
    "S71 = S71[16*RATE:88*RATE]\n",
    "S72 = S72[86*RATE:328*RATE]\n",
    "S73 = S73[116*RATE:260*RATE]\n",
    "S74 = S74[112*RATE:286*RATE]\n",
    "S81 = S81[0:78*RATE]\n",
    "S82 = S82[84*RATE:189*RATE]\n",
    "S83 = S83[130*RATE:312*RATE]\n",
    "S91 = S91[0:45*RATE]\n",
    "S92 = S92[50*RATE:108*RATE]\n",
    "S93 = S93[72*RATE:228*RATE]\n",
    "S94 = S94[68*RATE:258*RATE]\n",
    "\n",
    "B11 = B11[4*RATE:484*RATE]\n",
    "B12 = B12[4*RATE:382*RATE]\n",
    "B13 = B13[0*RATE:280*RATE]\n",
    "B21 = B21[4*RATE:157*RATE]\n",
    "B22 = B22[4*RATE:170*RATE]\n",
    "B23 = B23[8*RATE:166*RATE]\n",
    "B31 = B31[15*RATE:146*RATE]\n",
    "B32 = B32[12*RATE:258*RATE]\n",
    "B33 = B33[12*RATE:177*RATE]\n",
    "B41 = B41[10*RATE:109*RATE]\n",
    "B42 = B42[6*RATE:64*RATE]\n",
    "B43 = B43[6*RATE:88*RATE]\n",
    "B51 = B51[8*RATE:78*RATE]\n",
    "B52 = B52[4*RATE:268*RATE]\n",
    "B53 = B53[8*RATE:97*RATE]\n",
    "B54 = B54[4*RATE:123*RATE]\n",
    "B61 = B61[4*RATE:205*RATE]\n",
    "B62 = B62[4*RATE:135*RATE]\n",
    "B63 = B63[6*RATE:124*RATE]\n",
    "B71 = B71[4*RATE:296*RATE]\n",
    "B72 = B72[4*RATE:204*RATE]\n",
    "B73 = B73[10*RATE:303*RATE]\n",
    "B81 = B81[6*RATE:182*RATE]\n",
    "B82 = B82[6*RATE:183*RATE]\n",
    "B83 = B83[10*RATE:219*RATE]\n",
    "B91 = B91[4*RATE:201*RATE]\n",
    "B92 = B92[6*RATE:138*RATE]\n",
    "B93 = B93[0*RATE:158*RATE]\n",
    " \n",
    "signals_list = [\"G32h\", \"G41h\", \"G42h\", \"G43b\",\n",
    "              \"S11\", \"S12\", \"S13\", \"S14\", \"S21\", \"S22\", \"S23\", \"S31\", \"S32\", \"S33\",\n",
    "              \"S41\", \"S42\", \"S43\", \"S51\", \"S52\", \"S53\", \"S54\", \"S61\", \"S62\", \"S63\",\n",
    "              \"S71\", \"S72\", \"S73\", \"S74\", \"S81\", \"S82\", \"S83\", \"S91\", \"S92\", \"S93\", \"S94\",\n",
    "              \"B11\", \"B12\", \"B13\", \"B21\", \"B22\", \"B23\", \"B31\", \"B32\", \"B33\",\n",
    "              \"B41\", \"B42\", \"B43\", \"B51\", \"B52\", \"B53\", \"B54\", \"B61\", \"B62\", \"B63\", \n",
    "              \"B71\", \"B72\", \"B73\", \"B81\", \"B82\", \"B83\", \"B91\", \"B92\", \"B93\"]\n",
    "\n",
    "def check_all():\n",
    "    for signals in signals_list:\n",
    "        print(signals, eval(signals).shape)\n",
    "check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pick_signal(signals):\n",
    "  sample_size = int(RATE)        # int(RATE/2)\n",
    "  sample_step = int(sample_size/2) # int(RATE/4)\n",
    "  sample_data = []\n",
    "  for i in tqdm(range((len(signals)-sample_size) // sample_step)):\n",
    "    sample_data.append(signals[i*sample_step : (i*sample_step+sample_size)])\n",
    "  sample_data = np.stack(sample_data)\n",
    "  sample_data = np.squeeze(sample_data)\n",
    "  return sample_data\n",
    "\n",
    "G32h = pick_signal(G32h)\n",
    "G41h = pick_signal(G41h)\n",
    "G42h = pick_signal(G42h)\n",
    "G43b = pick_signal(G43b)\n",
    "\n",
    "S11 = pick_signal(S11)\n",
    "S12 = pick_signal(S12)\n",
    "S13 = pick_signal(S13)\n",
    "S14 = pick_signal(S14)\n",
    "S21 = pick_signal(S21)\n",
    "S22 = pick_signal(S22)\n",
    "S23 = pick_signal(S23)\n",
    "S31 = pick_signal(S31)\n",
    "S32 = pick_signal(S32)\n",
    "S33 = pick_signal(S33)\n",
    "S41 = pick_signal(S41)\n",
    "S42 = pick_signal(S42)\n",
    "S43 = pick_signal(S43)\n",
    "S51 = pick_signal(S51)\n",
    "S52 = pick_signal(S52)\n",
    "S53 = pick_signal(S53)\n",
    "S54 = pick_signal(S54)\n",
    "S61 = pick_signal(S61)\n",
    "S62 = pick_signal(S62)\n",
    "S63 = pick_signal(S63)\n",
    "S71 = pick_signal(S71)\n",
    "S72 = pick_signal(S72)\n",
    "S73 = pick_signal(S73)\n",
    "S74 = pick_signal(S74)\n",
    "S81 = pick_signal(S81)\n",
    "S82 = pick_signal(S82)\n",
    "S83 = pick_signal(S83)\n",
    "S91 = pick_signal(S91)\n",
    "S92 = pick_signal(S92)\n",
    "S93 = pick_signal(S93)\n",
    "S94 = pick_signal(S94)\n",
    "\n",
    "B11 = pick_signal(B11)\n",
    "B12 = pick_signal(B12)\n",
    "B13 = pick_signal(B13)\n",
    "B21 = pick_signal(B21)\n",
    "B22 = pick_signal(B22)\n",
    "B23 = pick_signal(B23)\n",
    "B31 = pick_signal(B31)\n",
    "B32 = pick_signal(B32)\n",
    "B33 = pick_signal(B33)\n",
    "B41 = pick_signal(B41)\n",
    "B42 = pick_signal(B42)\n",
    "B43 = pick_signal(B43)\n",
    "B51 = pick_signal(B51)\n",
    "B52 = pick_signal(B52)\n",
    "B53 = pick_signal(B53)\n",
    "B54 = pick_signal(B54)\n",
    "B61 = pick_signal(B61)\n",
    "B62 = pick_signal(B62)\n",
    "B63 = pick_signal(B63)\n",
    "B71 = pick_signal(B71)\n",
    "B72 = pick_signal(B72)\n",
    "B73 = pick_signal(B73)\n",
    "B81 = pick_signal(B81)\n",
    "B82 = pick_signal(B82)\n",
    "B83 = pick_signal(B83)\n",
    "B91 = pick_signal(B91)\n",
    "B92 = pick_signal(B92)\n",
    "B93 = pick_signal(B93)\n",
    "\n",
    "check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1D original\n",
    "def wave2wave(X, show):\n",
    "    if show==1:\n",
    "        print(\"waveform: \", X.shape)\n",
    "    return X\n",
    "\n",
    "# 1D spectrum\n",
    "def wave2spectrum(X, show):\n",
    "    spectrum = np.abs(np.fft.fft(X))\n",
    "    spectrum = spectrum[0:len(spectrum)//2]\n",
    "    if show==1:\n",
    "        print(\"spectrum: \", spectrum.shape)\n",
    "    return spectrum\n",
    "\n",
    "# 2D spectrogram\n",
    "def wave2spectrogram(X, show):\n",
    "    spectrogram = np.abs(librosa.stft(X))\n",
    "    spectrogram_db = librosa.amplitude_to_db(spectrogram, ref=np.max)\n",
    "    if show==1:\n",
    "        print(\"spectrogram_db: \", spectrogram_db.shape)\n",
    "    return spectrogram_db\n",
    "\n",
    "# 2D mfcc\n",
    "def wave2mfcc(X, show):\n",
    "    mfccs = librosa.feature.mfcc(y=X, sr=RATE)\n",
    "    if show==1:\n",
    "         print(\"mfccs: \", mfccs.shape)\n",
    "    return mfccs\n",
    "\n",
    "# 2D ptp\n",
    "def wave2ptp(X, show):\n",
    "    autocorr = np.correlate(X, X, mode='full')\n",
    "    time_delay = np.argmax(autocorr[len(autocorr)//2:]) + 1\n",
    "    embedding = np.array([X[:-2*time_delay], X[time_delay:-time_delay]]).T\n",
    "    if show==1:\n",
    "        plt.scatter(embedding[:, 0], embedding[:, 1])\n",
    "        plt.title('Phase Trajectory Plot')\n",
    "        plt.show()\n",
    "    return embedding\n",
    "\n",
    "# 2D urp\n",
    "def wave2urp(X, show):\n",
    "    urp = RecurrencePlot(threshold=None)\n",
    "    X_urp = urp.fit_transform(X.reshape(1, -1))[0]\n",
    "    if show==1:\n",
    "        plt.imshow(X_urp, cmap='rainbow', origin='lower')\n",
    "        plt.title('Unthresholded Recurrence Plot')\n",
    "        plt.colorbar(label='Intensity', fraction=0.0457, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return X_urp\n",
    "\n",
    "# 2D rp\n",
    "def wave2rp(X, show):\n",
    "    rp = RecurrencePlot(threshold='point', percentage=20)\n",
    "    X_rp = rp.fit_transform(X.reshape(1, -1))[0]\n",
    "    if show==1:\n",
    "        plt.imshow(X_rp, cmap='binary', origin='lower')\n",
    "        plt.title('Recurrence Plot')\n",
    "        plt.colorbar(label='Intensity', fraction=0.0457, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return X_rp\n",
    "\n",
    "#2D mtf\n",
    "def wave2mtf(X, show):\n",
    "    mtf = MarkovTransitionField(image_size=227)\n",
    "    X_mtf = mtf.fit_transform(X.reshape(1, -1))[0]\n",
    "    if show==1:\n",
    "        plt.imshow(X_mtf, cmap='rainbow', origin='lower')\n",
    "        plt.title('Markov Transition Field')\n",
    "        plt.colorbar(label='Intensity', fraction=0.0457, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return X_mtf\n",
    "\n",
    "# 2D ga(s)f\n",
    "def wave2gasf(X, show):\n",
    "    gasf = GramianAngularField(image_size=227, method='summation')\n",
    "    X_gasf = gasf.fit_transform(X.reshape(1, -1))[0]\n",
    "    if show==1:\n",
    "        plt.imshow(X_gasf, cmap='rainbow', origin='lower')\n",
    "        plt.title('Gramian Angular Summation Fields')\n",
    "        plt.colorbar(label='Intensity', fraction=0.0457, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return X_gasf\n",
    "\n",
    "# 2D ga(d)f\n",
    "def wave2gadf(X, show):\n",
    "    gadf = GramianAngularField(image_size=227, method='difference')\n",
    "    X_gadf = gadf.fit_transform(X.reshape(1, -1))[0]\n",
    "    if show==1:\n",
    "        plt.imshow(X_gadf, cmap='rainbow', origin='lower')\n",
    "        plt.title('Gramian Angular Difference Fields')\n",
    "        plt.colorbar(label='Intensity', fraction=0.0457, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return X_gadf\n",
    "\n",
    "# SIGNAL = G32h[0]\n",
    "print(\"signal shape: \", SIGNAL.shape)\n",
    "wave2wave(SIGNAL, 1)\n",
    "wave2spectrum(SIGNAL, 1)\n",
    "wave2spectrogram(SIGNAL, 1)\n",
    "wave2mfcc(SIGNAL, 1)\n",
    "wave2ptp(SIGNAL, 1)\n",
    "wave2urp(SIGNAL, 1)\n",
    "wave2rp(SIGNAL, 1)\n",
    "wave2mtf(SIGNAL, 1)\n",
    "wave2gasf(SIGNAL, 1)\n",
    "wave2gadf(SIGNAL, 1)\n",
    "SIGNAL = SIGNAL[0:227]\n",
    "print(\"signal shape: \", SIGNAL.shape)\n",
    "wave2wave(SIGNAL, 1)\n",
    "wave2spectrum(SIGNAL, 1)\n",
    "wave2spectrogram(SIGNAL, 1)\n",
    "wave2mfcc(SIGNAL, 1)\n",
    "wave2ptp(SIGNAL, 1)\n",
    "wave2urp(SIGNAL, 1)\n",
    "wave2rp(SIGNAL, 1)\n",
    "wave2mtf(SIGNAL, 1)\n",
    "wave2gasf(SIGNAL, 1)\n",
    "wave2gadf(SIGNAL, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def wave2others(signals):\n",
    "    function = wave2mfcc\n",
    "    results = []\n",
    "    if function == wave2rp or function == wave2urp:\n",
    "        random.seed(42)\n",
    "        shorter_length = 227\n",
    "        for signal in tqdm(signals):\n",
    "            shorter_arrays = [signal[i:i+shorter_length] for i in range(len(signal) - shorter_length + 1)]\n",
    "            signal = random.choice(shorter_arrays)\n",
    "            result = wave2spectrum(signal, 0)\n",
    "            result = function(signal, 0)\n",
    "            results.append(result)\n",
    "    else:\n",
    "        for signal in tqdm(signals):\n",
    "            result = wave2spectrum(signal, 0)\n",
    "            result = function(signal, 0)\n",
    "            results.append(result)\n",
    "    results = np.array(results)\n",
    "    return results\n",
    "\n",
    "G32h = wave2others(G32h)\n",
    "G41h = wave2others(G41h)\n",
    "G42h = wave2others(G42h)\n",
    "G43b = wave2others(G43b)\n",
    "\n",
    "S11 = wave2others(S11)\n",
    "S12 = wave2others(S12)\n",
    "S13 = wave2others(S13)\n",
    "S14 = wave2others(S14)\n",
    "S21 = wave2others(S21)\n",
    "S22 = wave2others(S22)\n",
    "S23 = wave2others(S23)\n",
    "S31 = wave2others(S31)\n",
    "S32 = wave2others(S32)\n",
    "S33 = wave2others(S33)\n",
    "S41 = wave2others(S41)\n",
    "S42 = wave2others(S42)\n",
    "S43 = wave2others(S43)\n",
    "S51 = wave2others(S51)\n",
    "S52 = wave2others(S52)\n",
    "S53 = wave2others(S53)\n",
    "S54 = wave2others(S54)\n",
    "S61 = wave2others(S61)\n",
    "S62 = wave2others(S62)\n",
    "S63 = wave2others(S63)\n",
    "S71 = wave2others(S71)\n",
    "S72 = wave2others(S72)\n",
    "S73 = wave2others(S73)\n",
    "S74 = wave2others(S74)\n",
    "S81 = wave2others(S81)\n",
    "S82 = wave2others(S82)\n",
    "S83 = wave2others(S83)\n",
    "S91 = wave2others(S91)\n",
    "S92 = wave2others(S92)\n",
    "S93 = wave2others(S93)\n",
    "S94 = wave2others(S94)\n",
    "\n",
    "B11 = wave2others(B11)\n",
    "B12 = wave2others(B12)\n",
    "B13 = wave2others(B13)\n",
    "B21 = wave2others(B21)\n",
    "B22 = wave2others(B22)\n",
    "B23 = wave2others(B23)\n",
    "B31 = wave2others(B31)\n",
    "B32 = wave2others(B32)\n",
    "B33 = wave2others(B33)\n",
    "B41 = wave2others(B41)\n",
    "B42 = wave2others(B42)\n",
    "B43 = wave2others(B43)\n",
    "B51 = wave2others(B51)\n",
    "B52 = wave2others(B52)\n",
    "B53 = wave2others(B53)\n",
    "B54 = wave2others(B54)\n",
    "B61 = wave2others(B61)\n",
    "B62 = wave2others(B62)\n",
    "B63 = wave2others(B63)\n",
    "B71 = wave2others(B71)\n",
    "B72 = wave2others(B72)\n",
    "B73 = wave2others(B73)\n",
    "B81 = wave2others(B81)\n",
    "B82 = wave2others(B82)\n",
    "B83 = wave2others(B83)\n",
    "B91 = wave2others(B91)\n",
    "B92 = wave2others(B92)\n",
    "B93 = wave2others(B93)\n",
    "\n",
    "check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHVUZzXIE64f"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFaBo2s6K3Lk"
   },
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rock type(3-classes: 0_granite, 1_sandstone, 2_bas\n",
    "X_0 = np.concatenate((G32h, G41h, G42h, G43b), axis=0)\n",
    "X_1 = np.concatenate((S11, S12, S13, S14, S21, S22, S23, S31, S32, S33,\n",
    "                      S41, S42, S43, S51, S52, S53, S54, S61, S62, S63,\n",
    "                      S71, S72, S73, S74, S81, S82, S83, S91, S92, S93, S94), axis=0)\n",
    "X_2 = np.concatenate((B11, B12, B13, B21, B22, B23, B31, B32, B33,\n",
    "                      B41, B42, B43, B51, B52, B53, B54, B61, B62, B63,\n",
    "                      B71, B72, B73, B81, B82, B83, B91, B92, B93), axis=0)\n",
    "min_size = min(len(X_0), len(X_1), len(X_2))\n",
    "X_0 = X_0[np.random.choice(len(X_0), size=min_size, replace=False)]\n",
    "X_1 = X_1[np.random.choice(len(X_1), size=min_size, replace=False)]\n",
    "X_2 = X_2[np.random.choice(len(X_2), size=min_size, replace=False)]\n",
    "Y_0 = np.repeat(0, len(X_0))\n",
    "Y_1 = np.repeat(1, len(X_1))\n",
    "Y_2 = np.repeat(2, len(X_2))\n",
    "X_set = np.concatenate((X_0, X_1, X_2), axis=0)\n",
    "Y_set = np.concatenate((Y_0, Y_1, Y_2), axis=0)\n",
    "num_classes = len(np.unique(Y_set))\n",
    "\n",
    "# # Bit type(3-classes: 0_IDB, 1_PDC, 2_MMC)\n",
    "# X_0 = np.concatenate((G32h, G41h, G42h, G43b,\n",
    "#                       S11, S12, S13, S14, S21, S22, S23, S31, S32, S33,\n",
    "#                       B11, B12, B13, B21, B22, B23, B31, B32, B33), axis=0)\n",
    "# X_1 = np.concatenate((S41, S42, S43, S51, S52, S53, S54, S61, S62, S63,\n",
    "#                       B41, B42, B43, B51, B52, B53, B54, B61, B62, B63), axis=0)\n",
    "# X_2 = np.concatenate((S71, S72, S73, S74, S81, S82, S83, S91, S92, S93, S94,\n",
    "#                       B71, B72, B73, B81, B82, B83, B91, B92, B93), axis=0)\n",
    "# min_size = min(len(X_0), len(X_1), len(X_2))\n",
    "# X_0 = X_0[np.random.choice(len(X_0), size=min_size, replace=False)]\n",
    "# X_1 = X_1[np.random.choice(len(X_1), size=min_size, replace=False)]\n",
    "# X_2 = X_2[np.random.choice(len(X_2), size=min_size, replace=False)]\n",
    "# Y_0 = np.repeat(0, len(X_0))\n",
    "# Y_1 = np.repeat(1, len(X_1))\n",
    "# Y_2 = np.repeat(2, len(X_2))\n",
    "# X_set = np.concatenate((X_0, X_1, X_2), axis=0)\n",
    "# Y_set = np.concatenate((Y_0, Y_1, Y_2), axis=0)\n",
    "# num_classes = len(np.unique(Y_set)) \n",
    "\n",
    "print(type(X_0), X_0.shape, type(Y_0), type(Y_0[0]), Y_0.shape)\n",
    "print(type(X_1), X_1.shape, type(Y_1), type(Y_1[0]), Y_1.shape)\n",
    "print(type(X_2), X_2.shape, type(Y_2), type(Y_2[0]), Y_2.shape)\n",
    "print(type(X_set), X_set.shape, type(Y_set), type(Y_set[0]), Y_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzVAF5QwCFgM"
   },
   "source": [
    "### ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(X_set, Y_set, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(\"x_train:\", x_train.shape)\n",
    "# print(\"y_train:\", y_train.shape)  \n",
    "# print(\"x_test:\", x_test.shape)\n",
    "# print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # K-Nearest Neighbors (KNN)\n",
    "# def make_knn():\n",
    "#     model = KNeighborsClassifier(n_neighbors=num_classes) \n",
    "#     model.fit(x_train, y_train)\n",
    "#     return model\n",
    "\n",
    "# # Decision Tree Classifier\n",
    "# def make_dtc():\n",
    "#     model = DecisionTreeClassifier()\n",
    "#     model.fit(x_train, y_train)\n",
    "#     return model\n",
    "\n",
    "# # Random Forest Classifier\n",
    "# def make_rfc():\n",
    "#     model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#     model.fit(x_train, y_train)\n",
    "#     return model\n",
    "\n",
    "# # Naive Bayes Classifier\n",
    "# def make_nbc():\n",
    "#     model = GaussianNB()\n",
    "#     model.fit(x_train, y_train)\n",
    "#     return model\n",
    "\n",
    "# time0 = time.time()\n",
    "# model = make_nbc()\n",
    "# time1 = time.time()\n",
    "# y_pred = model.predict(x_test)\n",
    "# time2 = time.time()\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred, average='weighted')\n",
    "# recall = recall_score(y_test, y_pred, average='weighted')\n",
    "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "# classification_report = classification_report(y_test, y_pred)\n",
    "# confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "# time3 = time.time()\n",
    "\n",
    "# print(\"Train time:\", time1-time0)\n",
    "# print(\"Predict time:\", time2-time1)\n",
    "# print(\"Process time:\", time3-time2)\n",
    "# print(\"Function time:\", time3-time1)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1 Score:\", f1)\n",
    "# print(\"\\nClassification Report:\\n\", classification_report)\n",
    "# print(\"\\nConfusion Matrix:\\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # labels = ['granite', 'sandstone', 'basalt']\n",
    "# # fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# # sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Oranges', cbar=True, square=True,\n",
    "# #             xticklabels=labels, yticklabels=labels, ax=ax, cbar_kws={'label': 'Count'})\n",
    "# # fontsize = 12\n",
    "# # ax.set_xlabel('Predicted Label', fontsize=fontsize)\n",
    "# # ax.set_ylabel('True Label', fontsize=fontsize)\n",
    "# # ax.set_title('Confusion Matrix', fontsize=fontsize)\n",
    "# # ax.tick_params(axis='x', labelsize=fontsize)\n",
    "# # ax.tick_params(axis='y', labelsize=fontsize)\n",
    "# # plt.show()\n",
    "\n",
    "# # # Define the confusion matrix array\n",
    "# # confusion_matrix = np.array([[50, 5, 0],\n",
    "# #                              [3, 45, 2],\n",
    "# #                              [10, 8, 40]])\n",
    "# # Create a figure and axes\n",
    "# fig, ax = plt.subplots()\n",
    "# # Define the font size for the annotations\n",
    "# annot_font_family = 'Times New Roman'\n",
    "# annot_font_weight = 'bold'\n",
    "# annot_font_size = 18\n",
    "# # Plot the confusion matrix with custom font size for the annotations\n",
    "# sns.heatmap(confusion_matrix, annot=True, cmap='Oranges', fmt='d', xticklabels=False, yticklabels=False,\n",
    "#             annot_kws={'fontsize': annot_font_size,\n",
    "#                       #  'fontfamily': annot_font_family,\n",
    "#                        'fontweight': annot_font_weight}, ax=ax)\n",
    "# # Remove x-label, y-label, x-tick labels, and y-tick labels\n",
    "# ax.set_xlabel('')\n",
    "# ax.set_ylabel('')\n",
    "# ax.set_xticklabels([])\n",
    "# ax.set_yticklabels([])\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "# plt.savefig('cm.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_set = np.expand_dims(X_set, axis=-1)\n",
    "Y_set = to_categorical(Y_set, num_classes=num_classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_set, Y_set, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(\"y_train:\", y_train.shape)  \n",
    "print(\"x_test:\", x_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAWVESHNjlNW",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_1Dgap():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 3, activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def make_1Ddense():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 7, strides=2, activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(MaxPooling1D(3, strides=2, padding='same'))\n",
    "    model.add(Conv1D(32, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(32, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(32, 3, activation='relu', padding='same'))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def make_1Dalex():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(96, 11, strides=4, activation='relu', input_shape=x_train.shape[1:]))  # (227, 1)\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=2))\n",
    "    model.add(Conv1D(256, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=2))\n",
    "    model.add(Conv1D(384, 3, activation='relu'))\n",
    "    model.add(Conv1D(384, 3, activation='relu'))\n",
    "    model.add(Conv1D(256, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def make_1Dvgg():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 3, activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(512, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  \n",
    "    return model\n",
    "\n",
    "\n",
    "def make_2Dgap():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def make_2Ddense():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (7, 7), strides=(2, 2), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def make_2Dalex():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=x_train.shape[1:]))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Conv2D(256, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Conv2D(384, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(384, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  \n",
    "    return model\n",
    "\n",
    "def make_2Dvgg():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "time0 = time.time()\n",
    "model = make_2Dalex()\n",
    "time1 = time.time()\n",
    "model.summary()\n",
    "# visualkeras.layered_view(model,legend=True)\n",
    "# keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SV9UyRhCK9IS"
   },
   "source": [
    "#### Complete & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzdCmhMnBBZ3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time2 = time.time()\n",
    "model.compile(optimizer='adam',                # tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "              loss='categorical_crossentropy', # loss='binary_crossentropy'\n",
    "              metrics=['accuracy',\n",
    "                       keras.metrics.AUC(),\n",
    "                       keras.metrics.Precision(),\n",
    "                       keras.metrics.Recall()])\n",
    "\n",
    "callbacks = [\n",
    "            #  keras.callbacks.ModelCheckpoint(\"best_model.hdf5\",\n",
    "            #                                  monitor=\"loss\",\n",
    "            #                                  mode=\"min\",\n",
    "            #                                  save_best_only=True),\n",
    "#              keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "#                                            mode=\"min\",\n",
    "#                                            verbose=1,\n",
    "#                                            patience=10,\n",
    "#                                            restore_best_weights=True), \n",
    "             keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                               factor=0.2,\n",
    "                                               patience=2,\n",
    "                                               min_lr=0.000001),\n",
    "            # keras.callbacks.TensorBoard(log_dir=os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_logs\"),\n",
    "            #                             histogram_freq=1,\n",
    "            #                             write_graph=True, \n",
    "            #                             write_images=True),\n",
    "            ]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_split=0.2, \n",
    "                    epochs=200, \n",
    "                    batch_size=64, \n",
    "                    callbacks=callbacks, \n",
    "                    shuffle=True)\n",
    "time3 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3X-ecrEcpzO"
   },
   "source": [
    "#### Show model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrZoVNFOb-Ys"
   },
   "outputs": [],
   "source": [
    "y_test_true = np.argmax(y_test, axis=1)\n",
    "time4 = time.time()\n",
    "y_test_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "time5 = time.time()\n",
    "accuracy = accuracy_score(y_test_true, y_test_pred)\n",
    "precision = precision_score(y_test_true, y_test_pred, average='weighted')\n",
    "recall = recall_score(y_test_true, y_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test_true, y_test_pred, average='weighted')\n",
    "classification_report = classification_report(y_test_true, y_test_pred)\n",
    "confusion_matrix = confusion_matrix(y_test_true, y_test_pred)\n",
    "time6 = time.time()\n",
    "print(\"Train time:\", time1-time0+time3-time2)\n",
    "print(\"Predict time:\", time5-time4)\n",
    "print(\"Process time:\", time6-time5)\n",
    "print(\"Function time:\", time6-time4)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# # Define the confusion matrix array\n",
    "# confusion_matrix = np.array([[1181,    0,    0],\n",
    "#                              [   0, 1243,    0],\n",
    "#                              [   0,    0, 1224]])\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "# Define the font size for the annotations\n",
    "annot_font_family = 'Times New Roman'\n",
    "annot_font_weight = 'bold'\n",
    "annot_font_size = 18\n",
    "# Plot the confusion matrix with custom font size for the annotations\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', \n",
    "            cmap='Oranges', cbar=False, square=True,\n",
    "            xticklabels=False, yticklabels=False,\n",
    "            annot_kws={'fontsize': annot_font_size,\n",
    "                      #  'fontfamily': annot_font_family,\n",
    "                       'fontweight': annot_font_weight}, ax=ax)\n",
    "# Remove x-label, y-label, x-tick labels, and y-tick labels\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.savefig('cm.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy, test_auc, test_precision, test_recall = model.evaluate(x_test, y_test)\n",
    "print(\"test_loss: \", test_loss)\n",
    "print(\"test_accuracy: \", test_accuracy)\n",
    "print(\"test_auc: \", test_auc)\n",
    "print(\"test_precision: \", test_precision)\n",
    "print(\"test_recall: \", test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3X-ecrEcpzO"
   },
   "source": [
    "#### Save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = {\"y_test_true\":y_test_true, \"y_test_pred\":y_test_pred, \"test_loss\":test_loss, \"test_accuracy\":test_accuracy, \"test_auc\":test_auc, \"test_precision\":test_precision, \"test_recall\":test_recall}\n",
    "model.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_model.hdf5\"))\n",
    "np.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_history.npy\"), history.history)\n",
    "np.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_evaluation.npy\"), eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3X-ecrEcpzO"
   },
   "source": [
    "#### Load model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_model.hdf5\"))\n",
    "# hist = np.load(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_history.npy\"), allow_pickle=True).item()\n",
    "# eval_dict = np.load(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_evaluation.npy\"), allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3X-ecrEcpzO"
   },
   "source": [
    "#### Plot model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_metrics(history):\n",
    "  total_plots = len(history)\n",
    "  cols = total_plots // 2\n",
    "  rows = total_plots // cols\n",
    "  if total_plots % cols != 0:\n",
    "    rows += 1\n",
    "  pos = range(1, total_plots + 1)\n",
    "  plt.figure(figsize=(15, 10))\n",
    "  for i, (key, value) in enumerate(history.items()):\n",
    "    plt.subplot(rows, cols, pos[i])\n",
    "    plt.plot(range(len(value)), value)\n",
    "    plt.title(str(key))\n",
    "  plt.savefig(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/C_evaluation.png\"))\n",
    " \n",
    "plot_history_metrics(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAQJZnnvpeT0"
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJBJ9ZDJjr6M"
   },
   "source": [
    "### Data pre-treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxhwGp3yQDYH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X_set = np.concatenate((S11,S12,S13,S14,S21,S22,S23,S31,S32,S33,S41,S42,S43,S51,S52,S53,S54,S61,S62,S63,S71,S72,S73,S74,S81,S82,S83,S91,S92,S93,S94), axis=0)\n",
    "# X_set = X_set.reshape((X_set.shape[0], X_set.shape[1], 1))\n",
    "# S1Y = [0,0,0, 150, 200, 8]\n",
    "# S2Y = [0,0,0, 250, 250, 10]\n",
    "# S3Y = [0,0,0, 350, 150, 6]\n",
    "# S4Y = [0,1,0, 150, 250, 6]\n",
    "# S5Y = [0,1,0, 250, 150, 8]\n",
    "# S6Y = [0,1,0, 350, 200, 10]\n",
    "# S7Y = [0,0,1, 150, 150, 10]\n",
    "# S8Y = [0,0,1, 250, 200, 6]\n",
    "# S9Y = [0,0,1, 350, 250, 8]\n",
    "# S1L = len(S11)+len(S12)+len(S13)+len(S14)\n",
    "# S2L = len(S21)+len(S22)+len(S23)\n",
    "# S3L = len(S31)+len(S32)+len(S33)\n",
    "# S4L = len(S41)+len(S42)+len(S43)\n",
    "# S5L = len(S51)+len(S52)+len(S53)+len(S54)\n",
    "# S6L = len(S61)+len(S62)+len(S63)\n",
    "# S7L = len(S71)+len(S72)+len(S73)+len(S74)\n",
    "# S8L = len(S81)+len(S82)+len(S83)\n",
    "# S9L = len(S91)+len(S92)+len(S93)+len(S94)\n",
    "# S_1 = [S1Y for _ in range(S1L)]\n",
    "# S_2 = [S2Y for _ in range(S2L)]\n",
    "# S_3 = [S3Y for _ in range(S3L)]\n",
    "# S_4 = [S4Y for _ in range(S4L)]\n",
    "# S_5 = [S5Y for _ in range(S5L)]\n",
    "# S_6 = [S6Y for _ in range(S6L)]\n",
    "# S_7 = [S7Y for _ in range(S7L)]\n",
    "# S_8 = [S8Y for _ in range(S8L)]\n",
    "# S_9 = [S9Y for _ in range(S9L)]\n",
    "# Y_set = np.concatenate((S_1,S_2,S_3,S_4,S_5,S_6,S_7,S_8,S_9), axis=0)\n",
    "# num_targets = Y_set.shape[1]\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X_set, Y_set, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBrIMBV7G7SY"
   },
   "source": [
    "### Model establishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_j3H1g7HBHs",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "# from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# def make_cnn_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(64, 3, input_shape=x_train.shape[1:], padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv1D(64, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "#     model.add(Conv1D(128, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv1D(128, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "#     model.add(Conv1D(256, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv1D(256, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv1D(256, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "#     model.add(Conv1D(512, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv1D(512, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv1D(512, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "#     model.add(Conv1D(512, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv1D(512, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv1D(512, 3, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(256))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(4096))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(num_targets, activation='linear'))\n",
    "#     return model\n",
    "\n",
    "# model = make_cnn_model()\n",
    "# model.summary()\n",
    "# # keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ0MwcgcILMp"
   },
   "source": [
    "### Complete & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6jYNXtxIM-v",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# callbacks = [\n",
    "#             #  keras.callbacks.ModelCheckpoint(\"best_model.hdf5\",\n",
    "#             #                                  monitor=\"loss\",\n",
    "#             #                                  mode=\"min\",\n",
    "#             #                                  save_best_only=True),\n",
    "#              keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "#                                            mode=\"min\",\n",
    "#                                            verbose=1,\n",
    "#                                            patience=10,\n",
    "#                                            restore_best_weights=True), \n",
    "#              keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "#                                                factor=0.2,\n",
    "#                                                patience=2,\n",
    "#                                                min_lr=0.000001),\n",
    "#             # keras.callbacks.TensorBoard(log_dir=os.path.join(HOST_path, \"IDB_drilling_signal/outputs/R_logs\"),\n",
    "#             #                             histogram_freq=1,\n",
    "#             #                             write_graph=True, \n",
    "#             #                             write_images=True),\n",
    "#             ]\n",
    "\n",
    "# history = model.fit(x_train, y_train,\n",
    "#                     validation_split=0.2, \n",
    "#                     epochs=200, \n",
    "#                     batch_size=32, \n",
    "#                     # callbacks=callbacks, \n",
    "#                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_true = y_test\n",
    "# y_test_pred = model.predict(x_test)\n",
    "# test_loss = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlsB07lmcfgv"
   },
   "source": [
    "### Save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0zhpsGYLCRn"
   },
   "outputs": [],
   "source": [
    "# eval_dict = {\"y_test_true\":y_test_true, \"y_test_pred\":y_test_pred, \"test_loss\":test_loss}\n",
    "\n",
    "# model.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/R_model.hdf5\"))\n",
    "# np.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/R_history.npy\"), history.history)\n",
    "# np.save(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/R_evaluation.npy\"), eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# model = load_model(\"/home/svu/e1097232/IDB_drilling_signal/outputs/R_model.hdf5\")\n",
    "# hist = np.load(\"/home/svu/e1097232/IDB_drilling_signal/outputs/R_history.npy\", allow_pickle=True)\n",
    "# eval_dict = np.load(\"/home/svu/e1097232/IDB_drilling_signal/outputs/R_evaluation.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlsB07lmcfgv"
   },
   "source": [
    "### Plot model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Loss-Epoch\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model Loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train set', 'Test set'], loc='upper left')\n",
    "# plt.savefig(os.path.join(HOST_path, \"IDB_drilling_signal/outputs/R_loss.png\"))\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "aRDeP7mE7tsJ",
    "9GlMfmecSIlL",
    "9VhGIWuWCilI",
    "6QiZNlVU_GQp",
    "FzL5v10mD1Ks",
    "k1CWOHHRDeme",
    "7yF2rdDXjghc",
    "O-g1ikLWdx_9",
    "--lMQ8qPc0gN",
    "bM61yOJ5G93E",
    "P675rHgiXtsF",
    "nZQeTBkFdxGJ"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
