{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA_-eAkuEnLC"
      },
      "source": [
        "# Materials & Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Dqfh0oC9d7"
      },
      "source": [
        "## Prepare environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKhi2VbCKlKv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi\n",
        "!git clone \"https://github.com/sunwucheng/IDB_drilling_signal.git\" /content/drive/MyDrive/IDB_drilling_signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JJ3nLgyjX2H"
      },
      "source": [
        "## Display signal data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4rlRDFk7mas"
      },
      "source": [
        "### Load signal data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt6Ac0D3aTAx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.io as scio\n",
        "\n",
        "def read_matFile(signal_path):\n",
        "  signal_file = scio.loadmat(signal_path)\n",
        "  signal_value = signal_file['samples']\n",
        "  signal_value = np.squeeze(signal_value)\n",
        "  return signal_value\n",
        "\n",
        "def read_wavFile(signal_path):\n",
        "  signal_rate, signal_value = scio.wavfile.read(signal_path)\n",
        "  return signal_value, signal_rate\n",
        "\n",
        "import librosa\n",
        "\n",
        "def read_soundFile(signal_path):\n",
        "  signal_value, signal_rate = librosa.load(signal_path, sr=None, mono=True, offset=0.0, duration=None)\n",
        "  return signal_value, signal_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_yWjU4NvGWY"
      },
      "outputs": [],
      "source": [
        "RATE = 8192\n",
        "print(\"RATE: \", RATE, \"Hz (default in Matlab)\")\n",
        "\n",
        "S32h = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/3-2h.mat\")\n",
        "S41h = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-1h.mat\")\n",
        "S42h = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-2h.mat\")\n",
        "S43b = read_matFile(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-3b.mat\")\n",
        "print(\"---------------------------------------\")\n",
        "print(\"S32h : \", S32h.shape, len(S32h)/RATE, 's')\n",
        "print(\"S41h : \", S41h.shape, len(S41h)/RATE, 's')\n",
        "print(\"S42h : \", S42h.shape, len(S42h)/RATE, 's')\n",
        "print(\"S43b : \", S43b.shape, len(S43b)/RATE, 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRDeP7mE7tsJ"
      },
      "source": [
        "### Plot signal data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laACxPu7uQWP"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def displayWaveform(signal, rate):\n",
        "  plt.figure(figsize=(20,6))\n",
        "  max = np.max(np.absolute(signal))*1.2\n",
        "  time = np.arange(0, len(SIGNAL)) / RATE\n",
        "  # plt.plot(time, signal)\n",
        "  librosa.display.waveshow(signal, sr=rate)\n",
        "  plt.title(\"Time domain waveform of speech signal\")\n",
        "  plt.xlabel(\"time (s)\")\n",
        "  plt.ylabel(\"amplitude\")\n",
        "  plt.xlim(0,len(SIGNAL)/RATE)\n",
        "  ymin, ymax = plt.ylim()\n",
        "  ylim = np.maximum(np.abs(ymin), np.abs(ymax))\n",
        "  plt.ylim(-ylim, ylim)\n",
        "\n",
        "def displaySpectrum(signal, rate):\n",
        "  plt.figure(figsize=(20,6)) \n",
        "  s = np.fft.fft(signal)\n",
        "  m = np.abs(s)\n",
        "  # f = np.linspace(0, rate, len(m))\n",
        "  # plt.plot(f, m)\n",
        "  n = len(signal)\n",
        "  f = np.fft.fftfreq(n, 1/rate)\n",
        "  plt.plot(f[:n//2],m[:n//2])\n",
        "  plt.title(\"Frequency domain spectral line of speech signal\")\n",
        "  plt.xlabel(\"Frequency (Hz)\")\n",
        "  plt.ylabel(\"amplitude\")\n",
        "  plt.xlim(0, rate//2)\n",
        "\n",
        "def displaySpectrogram(signal, rate, fftlen):    \n",
        "  plt.figure(figsize=(8,6))\n",
        "  # plt.specgram(signal, NFFT=fftlen, Fs=rate, noverlap=int(fftlen*0.25), window=np.hanning(fftlen))\n",
        "  signal_db = librosa.amplitude_to_db(np.abs(librosa.stft(signal, hop_length=int(fftlen*0.25))), ref=np.max) \n",
        "  librosa.display.specshow(signal_db, sr=rate, hop_length=int(fftlen*0.25), x_axis='time', y_axis='linear')\n",
        "  plt.title('Linear-frequency power spectrogram')\n",
        "  plt.xlabel('time (s)')\n",
        "  plt.ylabel('Frequency (Hz)')\n",
        "  plt.colorbar(format=\"%+2.0f dB\")\n",
        "\n",
        "def displayMelspectrogram(signal, rate):\n",
        "  plt.figure(figsize=(8,6))\n",
        "  # melspectrogram = librosa.feature.melspectrogram(y=signal, sr=rate)\n",
        "  D = np.abs(librosa.stft(signal))**2\n",
        "  S = librosa.feature.melspectrogram(S=D, sr=rate)\n",
        "  S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "  img = librosa.display.specshow(S_dB, sr=rate, fmax=rate/2, x_axis='time', y_axis='mel') \n",
        "  plt.title('Mel-frequency spectrogram')\n",
        "  plt.colorbar(format='%+2.0f dB')\n",
        "\n",
        "def diaplayMFCC(signal, rate):\n",
        "  plt.figure(figsize=(8,6))\n",
        "  mfccs = librosa.feature.mfcc(y=signal, sr=rate)\n",
        "  librosa.display.specshow(mfccs, sr=rate, x_axis='time')\n",
        "\n",
        "def displayZCR(signal, rate):\n",
        "  plt.figure(figsize=(8,3))\n",
        "  zcrs = librosa.feature.zero_crossing_rate(signal)  \n",
        "  plt.plot(zcrs[0])\n",
        "\n",
        "from sklearn import preprocessing\n",
        "def normalize(x, axis=0):\n",
        "    return preprocessing.minmax_scale(x, axis=axis)\n",
        "\n",
        "def displayCentroids(signal, rate):\n",
        "  # spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=rate)[0]\n",
        "  # frames = range(len(spectral_centroids))\n",
        "  # times = librosa.frames_to_time(frames)\n",
        "  # librosa.display.waveshow(signal, sr=rate, alpha=0.4)\n",
        "  # plt.plot(times, normalize(spectral_centroids), color='r')\n",
        "\n",
        "  cent = librosa.feature.spectral_centroid(y=signal, sr=rate) \n",
        "  S, phase = librosa.magphase(librosa.stft(y=signal))\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  librosa.feature.spectral_centroid(S=S)\n",
        "  freqs, times, D = librosa.reassigned_spectrogram(signal, fill_nan=True)\n",
        "  librosa.feature.spectral_centroid(S=np.abs(D), freq=freqs)\n",
        "  times = librosa.times_like(cent)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  ax[0].semilogy(times, cent[0], label='Spectral centroid')\n",
        "  ax[0].set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])\n",
        "  ax[0].legend()\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[1])\n",
        "  ax[1].plot(times, cent.T, label='Spectral centroid', color='w')\n",
        "  ax[1].set(title='log Power spectrogram')\n",
        "  ax[1].legend(loc='lower right')\n",
        "\n",
        "def displayBandwidth(signal, rate):\n",
        "  # spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(y=signal+0.01, sr=rate)[0]\n",
        "  # spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(y=signal+0.01, sr=rate, p=3)[0]\n",
        "  # spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(y=signal+0.01, sr=rate, p=4)[0]\n",
        "  # librosa.display.waveshow(signal, sr=rate, alpha=0.4)\n",
        "  # normal2 = preprocessing.minmax_scale(spectral_bandwidth_2, axis=0)\n",
        "  # normal3 = preprocessing.minmax_scale(spectral_bandwidth_3, axis=0)\n",
        "  # normal4 = preprocessing.minmax_scale(spectral_bandwidth_4, axis=0)\n",
        "  # spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=rate)[0]\n",
        "  # frames = range(len(spectral_centroids))\n",
        "  # times = librosa.frames_to_time(frames)\n",
        "  # plt.plot(times, normal2, color='r')\n",
        "  # plt.plot(times, normal3, color='g')\n",
        "  # plt.plot(times, normal4, color='y')\n",
        "  # plt.legend(('p = 2', 'p = 3', 'p = 4'))\n",
        "\n",
        "  spec_bw = librosa.feature.spectral_bandwidth(y=signal, sr=rate)\n",
        "  S, phase = librosa.magphase(librosa.stft(y=signal))\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  librosa.feature.spectral_bandwidth(S=S)\n",
        "  freqs, times, D = librosa.reassigned_spectrogram(signal, fill_nan=True)\n",
        "  librosa.feature.spectral_bandwidth(S=np.abs(D), freq=freqs)\n",
        "  times = librosa.times_like(spec_bw)\n",
        "  centroid = librosa.feature.spectral_centroid(S=S)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  ax[0].semilogy(times, spec_bw[0], label='Spectral bandwidth')\n",
        "  ax[0].set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])\n",
        "  ax[0].legend()\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  librosa.display.specshow(S_db, y_axis='log', x_axis='time', ax=ax[1])\n",
        "  ax[1].set(title='log Power spectrogram')\n",
        "  ax[1].fill_between(times, np.maximum(0, centroid[0] - spec_bw[0]), np.minimum(centroid[0] + spec_bw[0], rate/2), alpha=0.5, label='Centroid +- bandwidth')\n",
        "  ax[1].plot(times, centroid[0], label='Spectral centroid', color='w')\n",
        "  ax[1].legend(loc='lower right')\n",
        "\n",
        "def displayRolloff(signal, rate):\n",
        "  # spectral_rolloff = librosa.feature.spectral_rolloff(y=signal+0.01, sr=rate)[0]\n",
        "  # librosa.display.waveshow(signal, sr=rate, alpha=0.4)\n",
        "  # spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=rate)[0]\n",
        "  # frames = range(len(spectral_centroids))\n",
        "  # times = librosa.frames_to_time(frames)\n",
        "  # normals = preprocessing.minmax_scale(spectral_rolloff, axis=0)\n",
        "  # plt.plot(times, normals, color='r')\n",
        "\n",
        "  librosa.feature.spectral_rolloff(y=signal, sr=rate)\n",
        "  rolloff = librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.99)\n",
        "  rolloff_min = librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.01)\n",
        "  S, phase = librosa.magphase(librosa.stft(signal))\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  librosa.feature.spectral_rolloff(S=S, sr=rate)\n",
        "  librosa.feature.spectral_rolloff(y=signal, sr=rate, roll_percent=0.95)\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  librosa.display.specshow(S_db, y_axis='log', x_axis='time', ax=ax)\n",
        "  ax.plot(librosa.times_like(rolloff), rolloff[0], label='Roll-off frequency (0.99)')\n",
        "  ax.plot(librosa.times_like(rolloff), rolloff_min[0], color='w', label='Roll-off frequency (0.01)')\n",
        "  ax.legend(loc='lower right')\n",
        "  ax.set(title='log Power spectrogram')\n",
        "\n",
        "def displayChromastft(signal, rate, fftlen):\n",
        "  # chromagram = librosa.feature.chroma_stft(signal, sr=rate, hop_length=int(fftlen*0.25))\n",
        "  # librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=fftlen*0.25, cmap='coolwarm')\n",
        "\n",
        "  S = np.abs(librosa.stft(signal))\n",
        "  chroma = librosa.feature.chroma_stft(S=S, sr=rate)\n",
        "  S = np.abs(librosa.stft(signal, n_fft=fftlen))**2\n",
        "  S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
        "  chroma = librosa.feature.chroma_stft(S=S, sr=rate)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[0])\n",
        "  fig.colorbar(img, ax=[ax[0]])\n",
        "  ax[0].label_outer()\n",
        "  img = librosa.display.specshow(chroma, x_axis='time', y_axis='chroma', ax=ax[1])\n",
        "  fig.colorbar(img, ax=[ax[1]])\n",
        "\n",
        "def displayChromacqt(signal, rate, n_chroma, n_fft):\n",
        "  chroma_stft = librosa.feature.chroma_stft(y=signal, sr=rate, n_chroma=n_chroma, n_fft=n_fft)\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
        "  img1 = librosa.display.specshow(chroma_stft, x_axis='time', y_axis='chroma', ax=ax[0])\n",
        "  ax[0].set(title='chroma_stft')\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  img2 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[1])\n",
        "  ax[1].set(title='chroma_cqt')\n",
        "  fig.colorbar(img2, ax=ax)\n",
        "\n",
        "def displayChromacens(signal, rate):\n",
        "  chroma_cens = librosa.feature.chroma_cens(y=signal, sr=rate)\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
        "  img1 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[0])\n",
        "  ax[0].set(title='chroma_cq')\n",
        "  ax[0].label_outer()\n",
        "  img2 = librosa.display.specshow(chroma_cens, x_axis='time', y_axis='chroma', ax=ax[1])\n",
        "  ax[1].set(title='chroma_cens')\n",
        "  fig.colorbar(img1, ax=ax)\n",
        "\n",
        "def displayChromavqt(signal, rate, n_bins):\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=signal, sr=rate, n_chroma=n_bins)\n",
        "  chroma_vq = librosa.feature.chroma_vqt(y=signal, sr=rate, intervals='ji5', bins_per_octave=n_bins)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "  img1 = librosa.display.specshow(chroma_cq, x_axis='time', y_axis='chroma', ax=ax[0], bins_per_octave=n_bins)\n",
        "  ax[0].set(ylabel='chroma_cqt')\n",
        "  ax[0].label_outer()\n",
        "\n",
        "  img2 = librosa.display.specshow(chroma_vq, y_axis='chroma_fjs', x_axis='time', ax=ax[1], bins_per_octave=n_bins, intervals='ji5')\n",
        "  ax[1].set(ylabel='chroma_vqt')\n",
        "  fig.colorbar(img2, ax=ax)\n",
        "\n",
        "def plot_wave(signal, rate):  \n",
        "  displayWaveform(signal, rate)\n",
        "  displaySpectrum(signal, rate)\n",
        "  displaySpectrogram(signal, rate, fftlen=512)\n",
        "  displayMelspectrogram(signal, rate)\n",
        "  diaplayMFCC(signal, rate)\n",
        "  displayZCR(signal, rate)\n",
        "  displayCentroids(signal, rate)\n",
        "  displayBandwidth(signal, rate)\n",
        "  displayRolloff(signal, rate)\n",
        "  displayChromastft(signal, rate, fftlen=512)\n",
        "  # displayChromacqt(signal, rate, n_chroma=12, n_fft=512)\n",
        "  # displayChromacens(signal, rate)\n",
        "  # displayChromavqt(signal, rate, n_bins=24)\n",
        "\n",
        "SIGNAL = S32h[-40*RATE:]\n",
        "plot_wave(SIGNAL, RATE)\n",
        "\n",
        "import IPython\n",
        "\n",
        "IPython.display.Audio(data=SIGNAL, rate=RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHVUZzXIE64f"
      },
      "source": [
        "# Rock type prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data pre-treatment"
      ],
      "metadata": {
        "id": "eFaBo2s6K3Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| signal| mat2wav | pick |\n",
        "| :---: | :---: | :---: |\n",
        "| S32h | 00:00-17:36 | 02:00-12:00 |\n",
        "| S41h | 01:21-14:03 | 02:00-12:00 |\n",
        "| S42h | 00:00-21:24 | 02:00-12:00 |\n",
        "| S43b | 01:01-37:31 | 02:00-12:00 14:00-24:00 26:00-36:00 |"
      ],
      "metadata": {
        "id": "wClPlpgoTGQ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYvGlEF8nYad"
      },
      "outputs": [],
      "source": [
        "def cut_signal(signal_series):\n",
        "\n",
        "  sample_size = int(RATE/2)         # 4096\n",
        "  sample_step = int(sample_size/4)  # 512\n",
        "  sample_data = []\n",
        "\n",
        "  for i in range((len(signal_series)-sample_size) // sample_step):\n",
        "    sample_data.append(signal_series[i*sample_step : (i*sample_step+sample_size)])\n",
        "\n",
        "  sample_data = np.stack(sample_data)\n",
        "  sample_data = np.squeeze(sample_data)\n",
        "\n",
        "  # np.random.seed(42)\n",
        "  # np.random.shuffle(sample_data)\n",
        "  \n",
        "  return sample_data\n",
        "\n",
        "S32hCX = cut_signal(S32h[120*RATE:720*RATE])\n",
        "S41hCX = cut_signal(S41h[120*RATE:720*RATE])\n",
        "S42hCX = cut_signal(S42h[120*RATE:720*RATE])\n",
        "S43bCX1 = cut_signal(S43b[120*RATE:720*RATE])\n",
        "S43bCX2 = cut_signal(S43b[840*RATE:1440*RATE])\n",
        "S43bCX3 = cut_signal(S43b[1560*RATE:2160*RATE])\n",
        "\n",
        "S32hCY = np.repeat(0, len(S32hCX))\n",
        "S41hCY = np.repeat(0, len(S41hCX))\n",
        "S42hCY = np.repeat(0, len(S42hCX))\n",
        "S43bCY1 = np.repeat(1, len(S43bCX1))\n",
        "S43bCY2 = np.repeat(1, len(S43bCX2))\n",
        "S43bCY3 = np.repeat(1, len(S43bCX3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4Puu0AAUTtI"
      },
      "outputs": [],
      "source": [
        "X_set = np.concatenate((S32hCX, S41hCX, S42hCX, S43bCX1, S43bCX2, S43bCX3), axis=0)\n",
        "X_set = X_set.reshape((X_set.shape[0], X_set.shape[1], 1))\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "Y_set = np.concatenate((S32hCY, S41hCY, S42hCY, S43bCY1, S43bCY2, S43bCY3), axis=0)\n",
        "num_classes = len(np.unique(Y_set))\n",
        "Y_set = to_categorical(Y_set, num_classes=num_classes)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_set, Y_set, test_size=0.33, random_state=42)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byeqEwa-jRXi"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del S32hCX, S41hCX, S42hCX, S43bCX1, S43bCX2, S43bCX3, S32hCY, S41hCY, S42hCY, S43bCY1, S43bCY2, S43bCY3, X_set, Y_set\n",
        "gc.collect()\n",
        "\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification model"
      ],
      "metadata": {
        "id": "CzVAF5QwCFgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D-VGG16"
      ],
      "metadata": {
        "id": "9GlMfmecSIlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\")(input_layer)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "eZ5qvHwdSH6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D pure FC"
      ],
      "metadata": {
        "id": "9VhGIWuWCilI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Flatten()(input_layer)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dense(x_train.shape[1], activation=\"relu\")(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "xdMn8YVQClKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D Autoencoder"
      ],
      "metadata": {
        "id": "6QiZNlVU_GQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.Conv1D(filters=64, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Dropout(rate=0.2)(x)\n",
        "  x = keras.Conv1D(filters=32, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Dropout(rate=0.2)(x)\n",
        "  x = keras.Conv1D(filters=16, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Dropout(rate=0.2)(x)\n",
        "  x = keras.Conv1DTranspose(filters=16, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Conv1DTranspose(filters=32, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Conv1DTranspose(filters=64, kernel_size=6, padding=\"same\", strides=2, activation=\"relu\")(x)\n",
        "  x = keras.Conv1DTranspose(filters=1, kernel_size=6, padding=\"same\")(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "LS-V8g5U_S28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D simple Conv"
      ],
      "metadata": {
        "id": "FzL5v10mD1Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.ReLU()(x)\n",
        "  x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "0t24MT2UD1W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D classical Conv"
      ],
      "metadata": {
        "id": "k1CWOHHRDeme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=32, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(input_layer)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=128, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=1024, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=2048, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "x9FVEGKLDdRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yF2rdDXjghc"
      },
      "source": [
        "### 1D multi Conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAWVESHNjlNW"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=32, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(input_layer)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=128, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=1024, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=2048, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(16, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV9UyRhCK9IS"
      },
      "source": [
        "## Compile&Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzdCmhMnBBZ3"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='sgd', \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy',\n",
        "                       keras.metrics.AUC(),\n",
        "                       keras.metrics.Precision(),\n",
        "                       keras.metrics.Recall()])\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                           mode=\"min\",\n",
        "                                           verbose=1,\n",
        "                                           patience=10,\n",
        "                                           restore_best_weights=True),\n",
        "             keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
        "                                               factor=0.2, \n",
        "                                               patience=2,\n",
        "                                               min_lr=0.000001),\n",
        "            #  keras.callbacks.ModelCheckpoint(\"best_model.hdf5\",\n",
        "            #                                  monitor=\"loss\",\n",
        "            #                                  mode=\"min\",\n",
        "            #                                  save_best_only=True),\n",
        "            #  keras.callbacks.TensorBoard(log_dir=\"/content/drive/MyDrive/IDB_drilling_signal/outputs/logs\",\n",
        "            #                              histogram_freq=1,\n",
        "            #                              write_graph=True, \n",
        "            #                              write_images=True),\n",
        "             ]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_split=0.2, \n",
        "                    epochs=300, \n",
        "                    batch_size=64, \n",
        "                    callbacks=callbacks, \n",
        "                    shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save/display model"
      ],
      "metadata": {
        "id": "G3X-ecrEcpzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/model.hdf5\")\n",
        "# model = load_model(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/model.hdf5\")\n",
        "np.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/history.npy\", history.history, allow_pickle=True)\n",
        "# hist = np.load(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/history.npy\", allow_pickle=True)\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir \"/content/drive/MyDrive/IDB_drilling_signal/outputs/logs\""
      ],
      "metadata": {
        "id": "QrZoVNFOb-Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZc9ctYii2-R"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot training metrics"
      ],
      "metadata": {
        "id": "s9AyT8foAqHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNbjUMfrBBb6"
      },
      "outputs": [],
      "source": [
        "def plot_history_metrics(history):\n",
        "  \n",
        "  total_plots = len(history)\n",
        "  cols = total_plots // 2\n",
        "  rows = total_plots // cols\n",
        "\n",
        "  if total_plots % cols != 0:\n",
        "    rows += 1\n",
        "\n",
        "  pos = range(1, total_plots + 1)\n",
        "\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  for i, (key, value) in enumerate(history.items()):\n",
        "    plt.subplot(rows, cols, pos[i])\n",
        "    plt.plot(range(len(value)), value)\n",
        "    plt.title(str(key))\n",
        "\n",
        "plot_history_metrics(history.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction on test set"
      ],
      "metadata": {
        "id": "ci0yz1lTAuMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy, test_auc, test_precision, tes_recall = model.evaluate(x_test, y_test)\n",
        "print(\"Test loss\", test_loss)\n",
        "print(\"Test accuracy\", test_accuracy)\n",
        "print(\"test_auc\", test_auc) \n",
        "print(\"test_precision\", test_precision) \n",
        "print(\"tesrecall\", tes_recall)"
      ],
      "metadata": {
        "id": "3IrZSNLsbAVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_true = np.argmax(y_test, axis=1)\n",
        "y_test_pred = model.predict(x_test)\n",
        "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
        "print(y_test_pred.shape)\n",
        "print(y_test_pred)\n",
        "np.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/y_test_true.npy\", y_test, allow_pickle=True)\n",
        "np.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/y_test_pred.npy\", y_test_pred, allow_pickle=True)"
      ],
      "metadata": {
        "id": "pbUnBKekdULL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSULLYM8dWk2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def show_cm(y_test_true, y_test_pred):\n",
        "\n",
        "  cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "  plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "  plt.xticks([0,1])\n",
        "  plt.yticks([0,1])\n",
        "  plt.xlabel(\"Predict\")\n",
        "  plt.ylabel(\"True\")\n",
        "  tn, fp, fn, tp = confusion_matrix(y_test_true, y_test_pred).ravel()\n",
        "  plt.text(x=0-0.1, y=0, s=\"TP:\"+str(tp), color='black')\n",
        "  plt.text(x=1-0.1, y=0, s=\"FN:\"+str(fn), color='black')\n",
        "  plt.text(x=0-0.1, y=1, s=\"FP:\"+str(fp), color='black')\n",
        "  plt.text(x=1-0.1, y=1, s=\"TN:\"+str(tn), color='black')\n",
        "  precision = tp/(tp + fp)\n",
        "  recall = tp/(tp + tn)\n",
        "  print(\"precision:\", precision)\n",
        "  print(\"recall:\", recall)\n",
        "  plt.show()\n",
        "\n",
        "show_cm(y_test_true, y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAQJZnnvpeT0"
      },
      "source": [
        "# Drilling parameter prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJBJ9ZDJjr6M"
      },
      "source": [
        "## Data pre-processment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| signal| Table | mat2wav |\n",
        "| :---: | :---: | :---: |\n",
        "| S32h | 15:25:43-15:43:19 | 00:00-17:36 |\n",
        "| S41h | 16:26:25-16:39:34 | 00:54-14:03 |\n",
        "| S42h | 16:55:23-17:16:31 | 00:00-21:08 |\n",
        "| S43b | 17:24:00-18:00:25 | 01:05-37:30 |"
      ],
      "metadata": {
        "id": "JUuoKno0HN9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S32hRX = S32h[0:1056*RATE]\n",
        "S41hRX = S41h[54*RATE:843*RATE]\n",
        "S42hRX = S42h[0:1268*RATE]\n",
        "S43bRX = S43b[65*RATE:2250*RATE]"
      ],
      "metadata": {
        "id": "LENd62hQbQcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_table(table_path, time_start, time_end):\n",
        "  SIGNAL_pd = pd.read_excel(table_path)\n",
        "  IPython.display.display(SIGNAL_pd)\n",
        "  SIGNAL_arr = SIGNAL_pd.values[time_start : time_end,1:-1]\n",
        "  print(type(SIGNAL_arr), SIGNAL_arr.shape, len(SIGNAL_arr)-1, \"s\")\n",
        "  print(SIGNAL_arr)\n",
        "  return SIGNAL_arr\n",
        "\n",
        "S32hRY = load_table(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/3-2h.xls\", 46, 1103)\n",
        "S41hRY = load_table(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-1h.xls\", 28, 818)\n",
        "S42hRY = load_table(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-2h.xls\", 56, 1325)\n",
        "S43bRY = load_table(\"/content/drive/MyDrive/IDB_drilling_signal/Rock_drilling_signal/experiment1/4-3b.xls\", 3, 2189)"
      ],
      "metadata": {
        "id": "VxhwGp3yQDYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enlarge_value(array, length):\n",
        "  L = array.shape[0]\n",
        "  W = array.shape[1]\n",
        "  new_section = np.zeros([(L-1)*length, W-1])\n",
        "  for i in range(L - 1):   \n",
        "    new_second = np.zeros([length, W-1])\n",
        "    for j in range(W - 1):\n",
        "      start_value = float(array[i, j+1])\n",
        "      end_value = float(array[i+1, j+1])\n",
        "      new_second[:,j] = np.linspace(start_value, end_value, length + 2)[1:-1]  \n",
        "    new_section[i*length:(i+1)*length,:] = new_second\n",
        "  return new_section\n",
        "\n",
        "S32hRY = enlarge_value(S32hRY, RATE)\n",
        "S41hRY = enlarge_value(S41hRY, RATE)\n",
        "S42hRY = enlarge_value(S42hRY, RATE)\n",
        "S43bRY = enlarge_value(S43bRY, RATE)"
      ],
      "metadata": {
        "id": "ePdzZ5gOdIiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujBYos05kr8Y"
      },
      "outputs": [],
      "source": [
        "def pick_value(signal, label):\n",
        "\n",
        "  sample_size = int(RATE/2)         # 4096\n",
        "  sample_step = int(sample_size/4)  # 512\n",
        "  sample_data = []\n",
        "  sample_idx = []\n",
        "\n",
        "  for i in range((len(signal)-sample_size) // sample_step):\n",
        "    sample_data.append(signal[i*sample_step : (i*sample_step+sample_size)])\n",
        "    sample_idx.append(i*sample_step + sample_size//2)\n",
        "\n",
        "  sample_data = np.stack(sample_data)\n",
        "  sample_data = np.squeeze(sample_data)\n",
        "  sample_label = label[sample_idx]\n",
        "  \n",
        "  return sample_data, sample_label\n",
        "\n",
        "S32hRX, S32hRY = pick_value(S32hRX, S32hRY)\n",
        "S41hRX, S41hRY = pick_value(S41hRX, S41hRY)\n",
        "S42hRX, S42hRY = pick_value(S42hRX, S42hRY)\n",
        "S43bRX, S43bRY = pick_value(S43bRX, S43bRY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_set = np.concatenate((S32hRX, S41hRX, S42hRX, S43bRX), axis=0)\n",
        "X_set = X_set.reshape((X_set.shape[0], X_set.shape[1], 1))\n",
        "\n",
        "Y_set = np.concatenate((S32hRY, S41hRY, S42hRY, S43bRY), axis=0)\n",
        "num_targets = Y_set.shape[1]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_set, Y_set, test_size=0.33, random_state=42)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(\"--------------\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "Yw5zUKLBsCEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del S32hRX, S41hRX, S42hRX, S43bRX, S32hRY, S41hRY, S42hRY, S43bRY, X_set, Y_set\n",
        "gc.collect()\n",
        "\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "BwASTH0DE_cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression model"
      ],
      "metadata": {
        "id": "JBrIMBV7G7SY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D-VGG16"
      ],
      "metadata": {
        "id": "O-g1ikLWdx_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\")(input_layer)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  output_layer = keras.layers.Dense(num_targets, activation=\"linear\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "GBPgP16pdyLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D classical Conv"
      ],
      "metadata": {
        "id": "--lMQ8qPc0gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=32, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(input_layer)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=128, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=1024, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=2048, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  output_layer = keras.layers.Dense(num_targets, activation=\"linear\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "IJZoiBx2c0mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D multi Conv"
      ],
      "metadata": {
        "id": "bM61yOJ5G93E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "  input_layer = keras.Input(shape=(x_train.shape[1:]))\n",
        "  x = keras.layers.Conv1D(filters=32, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(input_layer)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=64, kernel_size=9, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=128, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=256, kernel_size=6, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=1024, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Conv1D(filters=2048, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(4096, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  x = keras.layers.Dropout(0.2)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(16, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "  output_layer = keras.layers.Dense(num_targets, activation=\"linear\")(x)\n",
        "\n",
        "  return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = make_model()\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "-_j3H1g7HBHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P675rHgiXtsF"
      },
      "source": [
        "### Self-made autoencoder-2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f2YevYNV6SQ"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "input_size = 1024\n",
        "hidden_size = 256\n",
        "code_size = 64\n",
        "latent_dim = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7cLFMexV6Uj"
      },
      "outputs": [],
      "source": [
        "x = Input(shape=(input_size,))\n",
        "h1 = Dense(hidden_size, activation='relu')(x)\n",
        "h2 = Dense(code_size, activation='relu')(h1)\n",
        "l = Dense(latent_dim, activation='relu')(h2)\n",
        "h3 = Dense(code_size, activation='relu')(l)\n",
        "h4 = Dense(hidden_size, activation='relu')(h3)\n",
        "r = Dense(input_size, activation='sigmoid')(h4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WVEZFzLV6Ww"
      },
      "outputs": [],
      "source": [
        "autoencoder = Model(x, r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-iawz8ncfYL"
      },
      "outputs": [],
      "source": [
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "plt.figure()\n",
        "plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], c=Y_train)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2SBTshFV6ZW"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(X_train, X_train, \n",
        "                          batch_size=batch_size, \n",
        "                          epochs=epochs, \n",
        "                          verbose=1, \n",
        "                          validation_data=(X_test, X_test),\n",
        "                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFH2Exp5V6dV"
      },
      "outputs": [],
      "source": [
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "plt.figure()\n",
        "plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], c=Y_train)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZQeTBkFdxGJ"
      },
      "source": [
        "### Self-made autoencoder-3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrwffnUUdxGV"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "input_size = 1024\n",
        "hidden_size = 256\n",
        "code_size = 64\n",
        "latent_dim = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSlj0KThdxGW"
      },
      "outputs": [],
      "source": [
        "x = Input(shape=(input_size,))\n",
        "h1 = Dense(hidden_size, activation='relu')(x)\n",
        "h2 = Dense(code_size, activation='relu')(h1)\n",
        "l = Dense(latent_dim, activation='relu')(h2)\n",
        "h3 = Dense(code_size, activation='relu')(l)\n",
        "h4 = Dense(hidden_size, activation='relu')(h3)\n",
        "r = Dense(input_size, activation='sigmoid')(h4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD0qqHskdxGW"
      },
      "outputs": [],
      "source": [
        "autoencoder = Model(x, r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS_j5KvFdxGW"
      },
      "outputs": [],
      "source": [
        "# encoder = Model(x, l)\n",
        "# X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "# plt.figure()\n",
        "# plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], X_train_encoded[:, 2], c=Y_train)\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "\n",
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "ax.scatter(X_train_encoded[:,0], X_train_encoded[:,1], X_train_encoded[:,2], c=Y_train)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdAjjqAddxGX"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(X_train, X_train, \n",
        "                          batch_size=batch_size, \n",
        "                          epochs=epochs, \n",
        "                          verbose=1, \n",
        "                          validation_data=(X_test, X_test),\n",
        "                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBTz1HVSdxGX"
      },
      "outputs": [],
      "source": [
        "# encoder = Model(x, l)\n",
        "# X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "# plt.figure()\n",
        "# plt.scatter(X_train_encoded[:, 0], X_train_encoded[:, 1], X_train_encoded[:, 2], c=Y_train)\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "\n",
        "encoder = Model(x, l)\n",
        "X_train_encoded = encoder.predict(X_train, batch_size=batch_size)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "ax.scatter(X_train_encoded[:,0], X_train_encoded[:,1], X_train_encoded[:,2], c=Y_train)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile&Training"
      ],
      "metadata": {
        "id": "UZ0MwcgcILMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', \n",
        "              loss='mse')\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                           mode=\"min\",\n",
        "                                           verbose=1,\n",
        "                                           patience=10,\n",
        "                                           restore_best_weights=True),\n",
        "             keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
        "                                               factor=0.2, \n",
        "                                               patience=2,\n",
        "                                               min_lr=0.000001),\n",
        "            #  keras.callbacks.ModelCheckpoint(\"best_model.hdf5\",\n",
        "            #                                  monitor=\"loss\",\n",
        "            #                                  mode=\"min\",\n",
        "            #                                  save_best_only=True),\n",
        "            #  keras.callbacks.TensorBoard(log_dir=\"/content/drive/MyDrive/IDB_drilling_signal/outputs/logs\",\n",
        "            #                              histogram_freq=1,\n",
        "            #                              write_graph=True, \n",
        "            #                              write_images=True),\n",
        "             ]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_split=0.2, \n",
        "                    epochs=300, \n",
        "                    batch_size=64, \n",
        "                    callbacks=callbacks, \n",
        "                    shuffle=True)"
      ],
      "metadata": {
        "id": "I6jYNXtxIM-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save/display model"
      ],
      "metadata": {
        "id": "YlsB07lmcfgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/model.hdf5\")\n",
        "# model = load_model(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/model.hdf5\")\n",
        "np.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/history.npy\", history.history, allow_pickle=True)\n",
        "# hist = np.load(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/history.npy\", allow_pickle=True)\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir \"/content/drive/MyDrive/IDB_drilling_signal/outputs/logs\""
      ],
      "metadata": {
        "id": "iMu1W33fceVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "-ABNJsUsLAYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot training metrics"
      ],
      "metadata": {
        "id": "-_yH_D0XLHar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Loss-Epoch_default\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train set', 'Test set'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i0zhpsGYLCRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction on test set"
      ],
      "metadata": {
        "id": "01B9E2c0LXal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = model.predict(x_test)\n",
        "print(y_test_pred.shape)\n",
        "print(y_test_pred)\n",
        "np.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/y_test_true.npy\", y_test, allow_pickle=True)\n",
        "np.save(\"/content/drive/MyDrive/IDB_drilling_signal/outputs/y_test_pred.npy\", y_test_pred, allow_pickle=True)"
      ],
      "metadata": {
        "id": "1219OK17LXh-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aRDeP7mE7tsJ",
        "9GlMfmecSIlL",
        "9VhGIWuWCilI",
        "6QiZNlVU_GQp",
        "FzL5v10mD1Ks",
        "k1CWOHHRDeme",
        "7yF2rdDXjghc",
        "O-g1ikLWdx_9",
        "--lMQ8qPc0gN",
        "bM61yOJ5G93E",
        "P675rHgiXtsF",
        "nZQeTBkFdxGJ"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}